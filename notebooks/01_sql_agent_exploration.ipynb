{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0cb592",
   "metadata": {},
   "source": [
    "# SQL Query Agent with Ollama - Exploration Notebook\n",
    "\n",
    "**Sprint 1 Deliverable** | **DSM 1.0 Track**\n",
    "\n",
    "This notebook builds and evaluates a natural language to SQL agent using open-source LLMs running locally via Ollama. It serves as a text-to-code generation testbed -- SQL is a constrained language ideal for systematic evaluation.\n",
    "\n",
    "**Architecture:** LangGraph state graph with schema filtering, SQL validation (sqlglot), and error-correction retry loop. Design informed by DIN-SQL, MAC-SQL, and CHESS research.\n",
    "\n",
    "**Goals:**\n",
    "1. Verify environment (Ollama, models, database)\n",
    "2. Build LangGraph agent: `schema_filter` → `generate_sql` → `validate_query` → `execute_query` → `handle_error`\n",
    "3. Evaluate at least 2 models (sqlcoder:7b vs llama3.1:8b) on a curated test suite\n",
    "\n",
    "**References:**\n",
    "- Research: `docs/research/text_to_sql_state_of_art.md`\n",
    "- Plan: `docs/plans/PLAN.md`\n",
    "- Sprint plan: `docs/plans/sprint-1-plan.md`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e77273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine created: sqlite:///../data/chinook.db\n"
     ]
    }
   ],
   "source": [
    "# cell 2: Imports & Configuration\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "from langchain_ollama import ChatOllama\n",
    "import sqlglot\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "OLLAMA_BASE_URL = \"http://172.27.64.1:11434\"  # Ollama on Windows, accessed via WSL gateway\n",
    "DB_PATH = \"../data/chinook.db\"\n",
    "PRIMARY_MODEL = \"sqlcoder:7b\"\n",
    "BASELINE_MODEL = \"llama3.1:8b\"\n",
    "\n",
    "# Database engine\n",
    "engine = create_engine(f\"sqlite:///{DB_PATH}\")\n",
    "print(f\"Database engine created: {engine.url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc0fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinook Database: 11 tables\n",
      "\n",
      "Album\n",
      "   AlbumId: INTEGER (PK)\n",
      "   Title: NVARCHAR(160)\n",
      "   ArtistId: INTEGER\n",
      "   FK: ['ArtistId'] -> Artist.['ArtistId']\n",
      "\n",
      "Artist\n",
      "   ArtistId: INTEGER (PK)\n",
      "   Name: NVARCHAR(120)\n",
      "\n",
      "Customer\n",
      "   CustomerId: INTEGER (PK)\n",
      "   FirstName: NVARCHAR(40)\n",
      "   LastName: NVARCHAR(20)\n",
      "   Company: NVARCHAR(80)\n",
      "   Address: NVARCHAR(70)\n",
      "   City: NVARCHAR(40)\n",
      "   State: NVARCHAR(40)\n",
      "   Country: NVARCHAR(40)\n",
      "   PostalCode: NVARCHAR(10)\n",
      "   Phone: NVARCHAR(24)\n",
      "   Fax: NVARCHAR(24)\n",
      "   Email: NVARCHAR(60)\n",
      "   SupportRepId: INTEGER\n",
      "   FK: ['SupportRepId'] -> Employee.['EmployeeId']\n",
      "\n",
      "Employee\n",
      "   EmployeeId: INTEGER (PK)\n",
      "   LastName: NVARCHAR(20)\n",
      "   FirstName: NVARCHAR(20)\n",
      "   Title: NVARCHAR(30)\n",
      "   ReportsTo: INTEGER\n",
      "   BirthDate: DATETIME\n",
      "   HireDate: DATETIME\n",
      "   Address: NVARCHAR(70)\n",
      "   City: NVARCHAR(40)\n",
      "   State: NVARCHAR(40)\n",
      "   Country: NVARCHAR(40)\n",
      "   PostalCode: NVARCHAR(10)\n",
      "   Phone: NVARCHAR(24)\n",
      "   Fax: NVARCHAR(24)\n",
      "   Email: NVARCHAR(60)\n",
      "   FK: ['ReportsTo'] -> Employee.['EmployeeId']\n",
      "\n",
      "Genre\n",
      "   GenreId: INTEGER (PK)\n",
      "   Name: NVARCHAR(120)\n",
      "\n",
      "Invoice\n",
      "   InvoiceId: INTEGER (PK)\n",
      "   CustomerId: INTEGER\n",
      "   InvoiceDate: DATETIME\n",
      "   BillingAddress: NVARCHAR(70)\n",
      "   BillingCity: NVARCHAR(40)\n",
      "   BillingState: NVARCHAR(40)\n",
      "   BillingCountry: NVARCHAR(40)\n",
      "   BillingPostalCode: NVARCHAR(10)\n",
      "   Total: NUMERIC(10, 2)\n",
      "   FK: ['CustomerId'] -> Customer.['CustomerId']\n",
      "\n",
      "InvoiceLine\n",
      "   InvoiceLineId: INTEGER (PK)\n",
      "   InvoiceId: INTEGER\n",
      "   TrackId: INTEGER\n",
      "   UnitPrice: NUMERIC(10, 2)\n",
      "   Quantity: INTEGER\n",
      "   FK: ['TrackId'] -> Track.['TrackId']\n",
      "   FK: ['InvoiceId'] -> Invoice.['InvoiceId']\n",
      "\n",
      "MediaType\n",
      "   MediaTypeId: INTEGER (PK)\n",
      "   Name: NVARCHAR(120)\n",
      "\n",
      "Playlist\n",
      "   PlaylistId: INTEGER (PK)\n",
      "   Name: NVARCHAR(120)\n",
      "\n",
      "PlaylistTrack\n",
      "   PlaylistId: INTEGER (PK)\n",
      "   TrackId: INTEGER (PK)\n",
      "   FK: ['TrackId'] -> Track.['TrackId']\n",
      "   FK: ['PlaylistId'] -> Playlist.['PlaylistId']\n",
      "\n",
      "Track\n",
      "   TrackId: INTEGER (PK)\n",
      "   Name: NVARCHAR(200)\n",
      "   AlbumId: INTEGER\n",
      "   MediaTypeId: INTEGER\n",
      "   GenreId: INTEGER\n",
      "   Composer: NVARCHAR(220)\n",
      "   Milliseconds: INTEGER\n",
      "   Bytes: INTEGER\n",
      "   UnitPrice: NUMERIC(10, 2)\n",
      "   FK: ['MediaTypeId'] -> MediaType.['MediaTypeId']\n",
      "   FK: ['GenreId'] -> Genre.['GenreId']\n",
      "   FK: ['AlbumId'] -> Album.['AlbumId']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Database Schema Inspection\n",
    "\n",
    "inspector = inspect(engine)\n",
    "tables = inspector.get_table_names()\n",
    "\n",
    "print(f\"Chinook Database: {len(tables)} tables\\n\")\n",
    "\n",
    "schema_info = {}\n",
    "for table_name in tables:\n",
    "    columns = inspector.get_columns(table_name)\n",
    "    pk = inspector.get_pk_constraint(table_name)\n",
    "    fks = inspector.get_foreign_keys(table_name)\n",
    "    \n",
    "    schema_info[table_name] = {\n",
    "        \"columns\": columns,\n",
    "        \"pk\": pk.get(\"constrained_columns\", []),\n",
    "        \"fks\": fks,\n",
    "    }\n",
    "    \n",
    "    # Display\n",
    "    pk_cols = set(pk.get(\"constrained_columns\", []))\n",
    "    print(f\"{table_name}\")\n",
    "    for col in columns:\n",
    "        marker = \" (PK)\" if col[\"name\"] in pk_cols else \"\"\n",
    "        print(f\"   {col['name']}: {col['type']}{marker}\")\n",
    "    for fk in fks:\n",
    "        print(f\"   FK: {fk['constrained_columns']} -> {fk['referred_table']}.{fk['referred_columns']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c5b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row counts:\n",
      "  Album: 347 rows\n",
      "  Artist: 275 rows\n",
      "  Customer: 59 rows\n",
      "  Employee: 8 rows\n",
      "  Genre: 25 rows\n",
      "  Invoice: 412 rows\n",
      "  InvoiceLine: 2,240 rows\n",
      "  MediaType: 5 rows\n",
      "  Playlist: 18 rows\n",
      "  PlaylistTrack: 8,715 rows\n",
      "  Track: 3,503 rows\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Row Counts\n",
    "\n",
    "print(\"Row counts:\")\n",
    "with engine.connect() as conn:\n",
    "    for table_name in tables:\n",
    "        count = conn.execute(text(f\"SELECT COUNT(*) FROM [{table_name}]\")).scalar()\n",
    "        print(f\"  {table_name}: {count:,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72072f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running at http://172.27.64.1:11434\n",
      "Available models: 4\n",
      "\n",
      "  llama3.1:8b                    4.6 GB\n",
      "  sqlcoder:7b                    3.8 GB\n",
      "  gemma3:1b                      0.8 GB\n",
      "  llama3:latest                  4.3 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Verify Ollama Connectivity & Available Models\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\", timeout=10)\n",
    "    response.raise_for_status()\n",
    "    models = response.json().get(\"models\", [])\n",
    "    print(f\"Ollama is running at {OLLAMA_BASE_URL}\")\n",
    "    print(f\"Available models: {len(models)}\\n\")\n",
    "    for m in models:\n",
    "        size_gb = m.get(\"size\", 0) / (1024**3)\n",
    "        print(f\"  {m['name']:30s} {size_gb:.1f} GB\")\n",
    "except requests.ConnectionError:\n",
    "    print(f\"ERROR: Cannot connect to Ollama at {OLLAMA_BASE_URL}\")\n",
    "    print(\"Make sure Ollama is running on the Windows host.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde6f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sqlcoder:7b...\n",
      "  Response: AS \"column_name\" FROM DUAL UNION ALL SELECT 2 AS \"column_name\" FROM DUAL UNION ALL SELECT 3 AS \"colu\n",
      "  Latency: 31.9s\n",
      "\n",
      "Testing llama3.1:8b...\n",
      "  Response: `SELECT 1;`\n",
      "  Latency: 10.9s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test LLM Connectivity\n",
    "for model_name in [PRIMARY_MODEL, BASELINE_MODEL]:\n",
    "    print(f\"Testing {model_name}...\")\n",
    "    llm = ChatOllama(model=model_name, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(\"Return only the SQL: SELECT 1\")\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"  Response: {response.content.strip()[:100]}\")\n",
    "    print(f\"  Latency: {elapsed:.1f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77a67e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist:\n",
      "  Columns: ['ArtistId', 'Name']\n",
      "  [1, 'AC/DC']\n",
      "  [2, 'Accept']\n",
      "  [3, 'Aerosmith']\n",
      "\n",
      "Album:\n",
      "  Columns: ['AlbumId', 'Title', 'ArtistId']\n",
      "  [1, 'For Those About To Rock We Salute You', 1]\n",
      "  [2, 'Balls to the Wall', 2]\n",
      "  [3, 'Restless and Wild', 2]\n",
      "\n",
      "Track:\n",
      "  Columns: ['TrackId', 'Name', 'AlbumId', 'MediaTypeId', 'GenreId', 'Composer', 'Milliseconds', 'Bytes', 'UnitPrice']\n",
      "  [1, 'For Those About To Rock (We Salute You)', 1, 1, 1, 'Angus Young, Malcolm Young, Brian Johnson', 343719, 11170334, 0.99]\n",
      "  [2, 'Balls to the Wall', 2, 2, 1, 'U. Dirkschneider, W. Hoffmann, H. Frank, P. Baltes, S. Kaufmann, G. Hoffmann', 342562, 5510424, 0.99]\n",
      "  [3, 'Fast As a Shark', 3, 2, 1, 'F. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman', 230619, 3990994, 0.99]\n",
      "\n",
      "Customer:\n",
      "  Columns: ['CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'Phone', 'Fax', 'Email', 'SupportRepId']\n",
      "  [1, 'Luís', 'Gonçalves', 'Embraer - Empresa Brasileira de Aeronáutica S.A.', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', '+55 (12) 3923-5555', '+55 (12) 3923-5566', 'luisg@embraer.com.br', 3]\n",
      "  [2, 'Leonie', 'Köhler', None, 'Theodor-Heuss-Straße 34', 'Stuttgart', None, 'Germany', '70174', '+49 0711 2842222', None, 'leonekohler@surfeu.de', 5]\n",
      "  [3, 'François', 'Tremblay', None, '1498 rue Bélanger', 'Montréal', 'QC', 'Canada', 'H2G 1A7', '+1 (514) 721-4711', None, 'ftremblay@gmail.com', 3]\n",
      "\n",
      "Invoice:\n",
      "  Columns: ['InvoiceId', 'CustomerId', 'InvoiceDate', 'BillingAddress', 'BillingCity', 'BillingState', 'BillingCountry', 'BillingPostalCode', 'Total']\n",
      "  [1, 2, '2021-01-01 00:00:00', 'Theodor-Heuss-Straße 34', 'Stuttgart', None, 'Germany', '70174', 1.98]\n",
      "  [2, 4, '2021-01-02 00:00:00', 'Ullevålsveien 14', 'Oslo', None, 'Norway', '0171', 3.96]\n",
      "  [3, 8, '2021-01-03 00:00:00', 'Grétrystraat 63', 'Brussels', None, 'Belgium', '1000', 5.94]\n",
      "\n",
      "InvoiceLine:\n",
      "  Columns: ['InvoiceLineId', 'InvoiceId', 'TrackId', 'UnitPrice', 'Quantity']\n",
      "  [1, 1, 2, 0.99, 1]\n",
      "  [2, 1, 4, 0.99, 1]\n",
      "  [3, 2, 6, 0.99, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Sample Rows for Few-Shot Prompting\n",
    "sample_tables = [\"Artist\", \"Album\", \"Track\", \"Customer\", \"Invoice\", \"InvoiceLine\"]\n",
    "\n",
    "sample_rows = {}\n",
    "with engine.connect() as conn:\n",
    "    for table_name in sample_tables:\n",
    "        rows = conn.execute(text(f\"SELECT * FROM [{table_name}] LIMIT 3\")).fetchall()\n",
    "        keys = conn.execute(text(f\"SELECT * FROM [{table_name}] LIMIT 1\")).keys()\n",
    "        sample_rows[table_name] = {\"columns\": list(keys), \"rows\": rows}\n",
    "        \n",
    "        print(f\"{table_name}:\")\n",
    "        print(f\"  Columns: {list(keys)}\")\n",
    "        for row in rows:\n",
    "            print(f\"  {list(row)}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4de94",
   "metadata": {},
   "source": [
    "## Phase 2: Core Agent Build\n",
    "\n",
    "LangGraph agent with 5 nodes:\n",
    "1. **schema_filter** — select relevant tables for the question\n",
    "2. **generate_sql** — LLM generates SQL from question + filtered schema\n",
    "3. **validate_query** — sqlglot parses SQL, security check (block writes)\n",
    "4. **execute_query** — run against SQLite, capture results or errors\n",
    "5. **handle_error** — on failure, feed error back to LLM for retry (max 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c94ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentState defined with fields:\n",
      "  question: <class 'str'>\n",
      "  relevant_tables: list[str]\n",
      "  schema_text: <class 'str'>\n",
      "  generated_sql: <class 'str'>\n",
      "  is_valid: <class 'bool'>\n",
      "  validation_error: <class 'str'>\n",
      "  results: typing.Optional[list]\n",
      "  error: <class 'str'>\n",
      "  retry_count: <class 'int'>\n",
      "  model_name: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Agent State Definition\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str                    # User's natural language question\n",
    "    relevant_tables: list[str]       # Tables selected by schema_filter\n",
    "    schema_text: str                 # DDL/schema for relevant tables\n",
    "    generated_sql: str               # SQL produced by LLM\n",
    "    is_valid: bool                   # sqlglot parse + security check passed\n",
    "    validation_error: str            # Error message if validation fails\n",
    "    results: Optional[list]          # Query results from SQLite\n",
    "    error: str                       # Execution error message\n",
    "    retry_count: int                 # Current retry attempt (max 3)\n",
    "    model_name: str                  # Which Ollama model to use\n",
    "\n",
    "print(\"AgentState defined with fields:\")\n",
    "for field, ftype in AgentState.__annotations__.items():\n",
    "    print(f\"  {field}: {ftype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb08fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many albums does each artist have?\n",
      "Selected tables (2): ['Album', 'Artist']\n",
      "Schema text length: 219 chars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relevant_tables': ['Album', 'Artist'],\n",
       " 'schema_text': \"CREATE TABLE Album (AlbumId INTEGER, Title NVARCHAR(160), ArtistId INTEGER);\\n-- Sample: (1, 'For Those About To Rock We Salute You', 1)\\nCREATE TABLE Artist (ArtistId INTEGER, Name NVARCHAR(120));\\n-- Sample: (1, 'AC/DC')\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10: Node 1 — Schema Filter\n",
    "def schema_filter(state: AgentState) -> dict:\n",
    "    \"\"\"Select relevant tables based on question keywords.\"\"\"\n",
    "    question_lower = state[\"question\"].lower()\n",
    "    question_words = set(question_lower.replace(\"?\", \"\").replace(\",\", \"\").split())\n",
    "    \n",
    "    scored_tables = []\n",
    "    for table_name, info in schema_info.items():\n",
    "        score = 0\n",
    "        table_lower = table_name.lower()\n",
    "        \n",
    "        # Table name match (strongest signal)\n",
    "        if table_lower in question_lower:\n",
    "            score += 3\n",
    "        # Partial table name match\n",
    "        for word in question_words:\n",
    "            if word in table_lower or table_lower in word:\n",
    "                score += 2\n",
    "        # Column name match\n",
    "        for col in info[\"columns\"]:\n",
    "            col_lower = col[\"name\"].lower()\n",
    "            if col_lower in question_lower:\n",
    "                score += 1\n",
    "            for word in question_words:\n",
    "                if word in col_lower:\n",
    "                    score += 0.5\n",
    "        \n",
    "        if score > 0:\n",
    "            scored_tables.append((table_name, score))\n",
    "    \n",
    "    # Sort by score, take top tables; always include at least FK-connected tables\n",
    "    scored_tables.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected = [t[0] for t in scored_tables[:5]]  # max 5 tables\n",
    "    \n",
    "    # Add FK-connected tables for selected tables\n",
    "    for table_name in list(selected):\n",
    "        for fk in schema_info[table_name][\"fks\"]:\n",
    "            referred = fk[\"referred_table\"]\n",
    "            if referred not in selected:\n",
    "                selected.append(referred)\n",
    "    \n",
    "    # Fallback: if nothing matched, include all tables\n",
    "    if not selected:\n",
    "        selected = list(schema_info.keys())\n",
    "    \n",
    "    # Build schema text for selected tables\n",
    "    schema_lines = []\n",
    "    for table_name in selected:\n",
    "        info = schema_info[table_name]\n",
    "        cols = \", \".join(\n",
    "            f\"{c['name']} {c['type']}\" for c in info[\"columns\"]\n",
    "        )\n",
    "        schema_lines.append(f\"CREATE TABLE {table_name} ({cols});\")\n",
    "        # Add sample rows\n",
    "        if table_name in sample_rows:\n",
    "            sr = sample_rows[table_name]\n",
    "            schema_lines.append(f\"-- Sample: {sr['rows'][0]}\")\n",
    "    \n",
    "    schema_text = \"\\n\".join(schema_lines)\n",
    "    \n",
    "    print(f\"Question: {state['question']}\")\n",
    "    print(f\"Selected tables ({len(selected)}): {selected}\")\n",
    "    print(f\"Schema text length: {len(schema_text)} chars\")\n",
    "    \n",
    "    return {\"relevant_tables\": selected, \"schema_text\": schema_text}\n",
    "\n",
    "# Quick test\n",
    "test_state = {\n",
    "    \"question\": \"How many albums does each artist have?\",\n",
    "    \"relevant_tables\": [], \"schema_text\": \"\", \"generated_sql\": \"\",\n",
    "    \"is_valid\": False, \"validation_error\": \"\", \"results\": None,\n",
    "    \"error\": \"\", \"retry_count\": 0, \"model_name\": PRIMARY_MODEL,\n",
    "}\n",
    "schema_filter(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b4fb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many albums does each artist have?\n",
      "Selected tables (2): ['Album', 'Artist']\n",
      "Schema text length: 219 chars\n",
      "Model: sqlcoder:7b\n",
      "Generated SQL: \n",
      "Latency: 8.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_sql': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 11: Node 2 — Generate SQL\n",
    "SQL_PROMPT_TEMPLATE = \"\"\"You are a SQL expert. Generate a SQLite-compatible SELECT query for the question below.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "Rules:\n",
    "- Return ONLY the SQL query, no explanation\n",
    "- Use only SELECT statements\n",
    "- Use only tables and columns from the schema above\n",
    "- Use SQLite syntax\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "SQL:\"\"\"\n",
    "\n",
    "def generate_sql(state: AgentState) -> dict:\n",
    "    \"\"\"Generate SQL from question + filtered schema using LLM.\"\"\"\n",
    "    prompt = SQL_PROMPT_TEMPLATE.format(\n",
    "        schema_text=state[\"schema_text\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOllama(\n",
    "        model=state[\"model_name\"],\n",
    "        base_url=OLLAMA_BASE_URL,\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    # Clean response: strip markdown fences and whitespace\n",
    "    sql = response.content.strip()\n",
    "    sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    print(f\"Model: {state['model_name']}\")\n",
    "    print(f\"Generated SQL: {sql}\")\n",
    "    print(f\"Latency: {elapsed:.1f}s\")\n",
    "    \n",
    "    return {\"generated_sql\": sql}\n",
    "\n",
    "# Quick test\n",
    "test_state_filtered = {**test_state, **schema_filter(test_state)}\n",
    "generate_sql(test_state_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7ed05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generic prompt ===\n",
      "Response: ''\n",
      "Latency: 22.5s\n",
      "\n",
      "=== sqlcoder-style prompt ===\n",
      "Response: 'SELECT a.artistid, COUNT(*) AS num_albums FROM album a GROUP BY a.artistid;\n",
      "```'\n",
      "Latency: 5.5s\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Diagnose sqlcoder prompt format\n",
    "SQLCODER_PROMPT_TEMPLATE = \"\"\"### Task\n",
    "Generate a SQL query to answer the following question:\n",
    "`{question}`\n",
    "\n",
    "### Database Schema\n",
    "{schema_text}\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQL query that answers `{question}`:\n",
    "```sql\n",
    "\"\"\"\n",
    "\n",
    "prompt_generic = SQL_PROMPT_TEMPLATE.format(\n",
    "    schema_text=test_state_filtered[\"schema_text\"],\n",
    "    question=test_state_filtered[\"question\"],\n",
    ")\n",
    "prompt_sqlcoder = SQLCODER_PROMPT_TEMPLATE.format(\n",
    "    schema_text=test_state_filtered[\"schema_text\"],\n",
    "    question=test_state_filtered[\"question\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=PRIMARY_MODEL, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "\n",
    "print(\"=== Generic prompt ===\")\n",
    "t0 = time.time()\n",
    "r1 = llm.invoke(prompt_generic)\n",
    "print(f\"Response: '{r1.content.strip()[:200]}'\")\n",
    "print(f\"Latency: {time.time() - t0:.1f}s\\n\")\n",
    "\n",
    "print(\"=== sqlcoder-style prompt ===\")\n",
    "t0 = time.time()\n",
    "r2 = llm.invoke(prompt_sqlcoder)\n",
    "print(f\"Response: '{r2.content.strip()[:200]}'\")\n",
    "print(f\"Latency: {time.time() - t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb6d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many albums does each artist have?\n",
      "Selected tables (2): ['Album', 'Artist']\n",
      "Schema text length: 219 chars\n",
      "--- sqlcoder:7b ---\n",
      "Model: sqlcoder:7b\n",
      "Prompt: sqlcoder\n",
      "Generated SQL: SELECT a.artistid, COUNT(*) AS num_albums FROM album a GROUP BY a.artistid\n",
      "Latency: 4.0s\n",
      "\n",
      "--- llama3.1:8b ---\n",
      "Model: llama3.1:8b\n",
      "Prompt: generic\n",
      "Generated SQL: SELECT A.Name, COUNT(AlbumId) AS AlbumCount\n",
      "FROM Artist A\n",
      "JOIN Album ON A.ArtistId = Album.ArtistId\n",
      "GROUP BY A.Name\n",
      "Latency: 17.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_sql': 'SELECT A.Name, COUNT(AlbumId) AS AlbumCount\\nFROM Artist A\\nJOIN Album ON A.ArtistId = Album.ArtistId\\nGROUP BY A.Name'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 13: Node 2 (revised) — Generate SQL with model-aware prompts\n",
    "GENERIC_PROMPT = \"\"\"You are a SQL expert. Generate a SQLite-compatible SELECT query for the question below.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "Rules:\n",
    "- Return ONLY the SQL query, no explanation\n",
    "- Use only SELECT statements\n",
    "- Use only tables and columns from the schema above\n",
    "- Use SQLite syntax\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "SQL:\"\"\"\n",
    "\n",
    "SQLCODER_PROMPT = \"\"\"### Task\n",
    "Generate a SQL query to answer the following question:\n",
    "`{question}`\n",
    "\n",
    "### Database Schema\n",
    "{schema_text}\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQL query that answers `{question}`:\n",
    "```sql\n",
    "\"\"\"\n",
    "\n",
    "def generate_sql(state: AgentState) -> dict:\n",
    "    \"\"\"Generate SQL from question + filtered schema using LLM.\"\"\"\n",
    "    model = state[\"model_name\"]\n",
    "    \n",
    "    # Select prompt template based on model\n",
    "    if \"sqlcoder\" in model:\n",
    "        template = SQLCODER_PROMPT\n",
    "    else:\n",
    "        template = GENERIC_PROMPT\n",
    "    \n",
    "    prompt = template.format(\n",
    "        schema_text=state[\"schema_text\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOllama(model=model, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    # Clean response: strip markdown fences and whitespace\n",
    "    sql = response.content.strip()\n",
    "    sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    # Remove trailing semicolons for consistency\n",
    "    sql = sql.rstrip(\";\").strip()\n",
    "    \n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Prompt: {'sqlcoder' if 'sqlcoder' in model else 'generic'}\")\n",
    "    print(f\"Generated SQL: {sql}\")\n",
    "    print(f\"Latency: {elapsed:.1f}s\")\n",
    "    \n",
    "    return {\"generated_sql\": sql}\n",
    "\n",
    "# Test with both models\n",
    "test_state_filtered = {**test_state, **schema_filter(test_state)}\n",
    "print(\"--- sqlcoder:7b ---\")\n",
    "generate_sql(test_state_filtered)\n",
    "print()\n",
    "print(\"--- llama3.1:8b ---\")\n",
    "generate_sql({**test_state_filtered, \"model_name\": BASELINE_MODEL})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc0fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Valid query ---\n",
      "VALID: SELECT Name FROM Artist LIMIT 5...\n",
      "\n",
      "--- Blocked query ---\n",
      "BLOCKED: DROP detected\n",
      "\n",
      "--- Bad syntax ---\n",
      "INVALID: Invalid expression / Unexpected token. Line 1, Col: 15.\n",
      "  SELEC Name \u001b[4mFORM\u001b[0m Artist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_valid': False,\n",
       " 'validation_error': 'Invalid expression / Unexpected token. Line 1, Col: 15.\\n  SELEC Name \\x1b[4mFORM\\x1b[0m Artist'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 14: Node 3 — Validate Query\n",
    "BLOCKED_KEYWORDS = {\"INSERT\", \"UPDATE\", \"DELETE\", \"DROP\", \"ALTER\", \"CREATE\", \"TRUNCATE\"}\n",
    "\n",
    "def validate_query(state: AgentState) -> dict:\n",
    "    \"\"\"Validate SQL with sqlglot and block write operations.\"\"\"\n",
    "    sql = state[\"generated_sql\"]\n",
    "    \n",
    "    # Check for empty SQL\n",
    "    if not sql.strip():\n",
    "        print(\"INVALID: Empty SQL\")\n",
    "        return {\"is_valid\": False, \"validation_error\": \"LLM returned empty SQL\"}\n",
    "    \n",
    "    # Security check: block write operations\n",
    "    sql_upper = sql.upper()\n",
    "    for keyword in BLOCKED_KEYWORDS:\n",
    "        if keyword in sql_upper.split():\n",
    "            print(f\"BLOCKED: {keyword} detected\")\n",
    "            return {\"is_valid\": False, \"validation_error\": f\"Write operation blocked: {keyword}\"}\n",
    "    \n",
    "    # Syntax check with sqlglot\n",
    "    try:\n",
    "        parsed = sqlglot.parse(sql, read=\"sqlite\")\n",
    "        if not parsed or parsed[0] is None:\n",
    "            print(\"INVALID: sqlglot could not parse\")\n",
    "            return {\"is_valid\": False, \"validation_error\": \"sqlglot failed to parse SQL\"}\n",
    "        print(f\"VALID: {sql[:80]}...\")\n",
    "        return {\"is_valid\": True, \"validation_error\": \"\"}\n",
    "    except sqlglot.errors.ParseError as e:\n",
    "        print(f\"INVALID: {e}\")\n",
    "        return {\"is_valid\": False, \"validation_error\": str(e)}\n",
    "\n",
    "# Test valid query\n",
    "print(\"--- Valid query ---\")\n",
    "validate_query({\"generated_sql\": \"SELECT Name FROM Artist LIMIT 5\"})\n",
    "print()\n",
    "\n",
    "# Test blocked query\n",
    "print(\"--- Blocked query ---\")\n",
    "validate_query({\"generated_sql\": \"DROP TABLE Artist\"})\n",
    "print()\n",
    "\n",
    "# Test bad syntax\n",
    "print(\"--- Bad syntax ---\")\n",
    "validate_query({\"generated_sql\": \"SELEC Name FORM Artist\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60efd1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Valid execution ---\n",
      "Executed: SELECT Name FROM Artist LIMIT 5\n",
      "Rows returned: 5\n",
      "  ['AC/DC']\n",
      "  ['Accept']\n",
      "  ['Aerosmith']\n",
      "  ['Alanis Morissette']\n",
      "  ['Alice In Chains']\n",
      "\n",
      "--- Runtime error ---\n",
      "Execution error: (sqlite3.OperationalError) no such column: Foo\n",
      "[SQL: SELECT Foo FROM Artist]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results': None,\n",
       " 'error': '(sqlite3.OperationalError) no such column: Foo\\n[SQL: SELECT Foo FROM Artist]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 15: Node 4 — Execute Query\n",
    "def execute_query(state: AgentState) -> dict:\n",
    "    \"\"\"Execute validated SQL against the database.\"\"\"\n",
    "    sql = state[\"generated_sql\"]\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            rows = conn.execute(text(sql)).fetchmany(20)\n",
    "            results = [list(row) for row in rows]\n",
    "            print(f\"Executed: {sql[:80]}\")\n",
    "            print(f\"Rows returned: {len(results)}\")\n",
    "            for row in results[:5]:\n",
    "                print(f\"  {row}\")\n",
    "            if len(results) > 5:\n",
    "                print(f\"  ... ({len(results)} rows total)\")\n",
    "            return {\"results\": results, \"error\": \"\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Execution error: {e}\")\n",
    "        return {\"results\": None, \"error\": str(e)}\n",
    "\n",
    "# Test with a real query\n",
    "print(\"--- Valid execution ---\")\n",
    "execute_query({\"generated_sql\": \"SELECT Name FROM Artist LIMIT 5\"})\n",
    "print()\n",
    "\n",
    "# Test with a bad query (valid syntax but wrong column)\n",
    "print(\"--- Runtime error ---\")\n",
    "execute_query({\"generated_sql\": \"SELECT Foo FROM Artist\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f79f0dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry 1: SELECT a.\"ArtistId\", COUNT(a.\"AlbumId\") AS \"Number of Albums\" FROM \"Album\" a GRO\n",
      "Latency: 62.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_sql': 'SELECT a.\"ArtistId\", COUNT(a.\"AlbumId\") AS \"Number of Albums\" FROM \"Album\" a GROUP BY a.\"ArtistId\"',\n",
       " 'retry_count': 1,\n",
       " 'error': ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 16: Node 5 — Handle Error (Retry with Error Context)\n",
    "ERROR_REPAIR_GENERIC = \"\"\"The following SQL query produced an error. Fix it.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "Original question: {question}\n",
    "\n",
    "Failed SQL:\n",
    "{generated_sql}\n",
    "\n",
    "Error:\n",
    "{error}\n",
    "\n",
    "Return ONLY the corrected SQL query, no explanation.\n",
    "\n",
    "SQL:\"\"\"\n",
    "\n",
    "ERROR_REPAIR_SQLCODER = \"\"\"### Task\n",
    "The following SQL query produced an error. Fix the query to answer:\n",
    "`{question}`\n",
    "\n",
    "### Database Schema\n",
    "{schema_text}\n",
    "\n",
    "### Failed Query\n",
    "{generated_sql}\n",
    "\n",
    "### Error\n",
    "{error}\n",
    "\n",
    "### Corrected Answer\n",
    "```sql\n",
    "\"\"\"\n",
    "\n",
    "def handle_error(state: AgentState) -> dict:\n",
    "    \"\"\"Feed error back to LLM for SQL repair.\"\"\"\n",
    "    model = state[\"model_name\"]\n",
    "    \n",
    "    if \"sqlcoder\" in model:\n",
    "        template = ERROR_REPAIR_SQLCODER\n",
    "    else:\n",
    "        template = ERROR_REPAIR_GENERIC\n",
    "    \n",
    "    prompt = template.format(\n",
    "        schema_text=state[\"schema_text\"],\n",
    "        question=state[\"question\"],\n",
    "        generated_sql=state[\"generated_sql\"],\n",
    "        error=state[\"error\"],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOllama(model=model, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    sql = response.content.strip()\n",
    "    sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    sql = sql.rstrip(\";\").strip()\n",
    "    \n",
    "    new_retry = state[\"retry_count\"] + 1\n",
    "    print(f\"Retry {new_retry}: {sql[:80]}\")\n",
    "    print(f\"Latency: {elapsed:.1f}s\")\n",
    "    \n",
    "    return {\"generated_sql\": sql, \"retry_count\": new_retry, \"error\": \"\"}\n",
    "\n",
    "# Test: simulate a failed query with wrong column name\n",
    "test_error_state = {\n",
    "    **test_state_filtered,\n",
    "    \"generated_sql\": \"SELECT Foo FROM Artist\",\n",
    "    \"error\": \"(sqlite3.OperationalError) no such column: Foo\",\n",
    "    \"retry_count\": 0,\n",
    "}\n",
    "handle_error(test_error_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8e9654d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent compiled successfully\n",
      "Nodes: ['__start__', 'schema_filter', 'generate_sql', 'validate_query', 'execute_query', 'handle_error']\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Wire LangGraph State Graph\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def should_retry(state: AgentState) -> str:\n",
    "    \"\"\"Route after execute_query: retry on error or finish.\"\"\"\n",
    "    if state[\"error\"] and state[\"retry_count\"] < 3:\n",
    "        return \"handle_error\"\n",
    "    return END\n",
    "\n",
    "def check_validation(state: AgentState) -> str:\n",
    "    \"\"\"Route after validate_query: execute if valid, retry or stop.\"\"\"\n",
    "    if state[\"is_valid\"]:\n",
    "        return \"execute_query\"\n",
    "    if state[\"retry_count\"] < 3:\n",
    "        return \"handle_error\"\n",
    "    return END\n",
    "\n",
    "# Build graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"schema_filter\", schema_filter)\n",
    "workflow.add_node(\"generate_sql\", generate_sql)\n",
    "workflow.add_node(\"validate_query\", validate_query)\n",
    "workflow.add_node(\"execute_query\", execute_query)\n",
    "workflow.add_node(\"handle_error\", handle_error)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"schema_filter\")\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"schema_filter\", \"generate_sql\")\n",
    "workflow.add_edge(\"generate_sql\", \"validate_query\")\n",
    "workflow.add_conditional_edges(\"validate_query\", check_validation)\n",
    "workflow.add_conditional_edges(\"execute_query\", should_retry)\n",
    "workflow.add_edge(\"handle_error\", \"validate_query\")\n",
    "\n",
    "# Compile\n",
    "agent = workflow.compile()\n",
    "print(\"Agent compiled successfully\")\n",
    "print(f\"Nodes: {list(agent.nodes.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3199845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Question: How many albums does each artist have? Show artist name and count, top 5.\n",
      "Model: sqlcoder:7b\n",
      "============================================================\n",
      "Question: How many albums does each artist have? Show artist name and count, top 5.\n",
      "Selected tables (5): ['Artist', 'Album', 'Customer', 'Employee', 'Genre']\n",
      "Schema text length: 1159 chars\n",
      "Model: sqlcoder:7b\n",
      "Prompt: sqlcoder\n",
      "Generated SQL: SELECT a.\"Name\", COUNT(b.AlbumId) AS \"Number of Albums\" FROM Artist a JOIN Album b ON a.ArtistId = b.ArtistId GROUP BY a.\"Name\" ORDER BY \"Number of Albums\" DESC NULLS LAST LIMIT 5\n",
      "Latency: 19.0s\n",
      "VALID: SELECT a.\"Name\", COUNT(b.AlbumId) AS \"Number of Albums\" FROM Artist a JOIN Album...\n",
      "Executed: SELECT a.\"Name\", COUNT(b.AlbumId) AS \"Number of Albums\" FROM Artist a JOIN Album\n",
      "Rows returned: 5\n",
      "  ['Iron Maiden', 21]\n",
      "  ['Led Zeppelin', 14]\n",
      "  ['Deep Purple', 11]\n",
      "  ['U2', 10]\n",
      "  ['Metallica', 10]\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "SQL: SELECT a.\"Name\", COUNT(b.AlbumId) AS \"Number of Albums\" FROM Artist a JOIN Album b ON a.ArtistId = b.ArtistId GROUP BY a.\"Name\" ORDER BY \"Number of Albums\" DESC NULLS LAST LIMIT 5\n",
      "Valid: True\n",
      "Results: [['Iron Maiden', 21], ['Led Zeppelin', 14], ['Deep Purple', 11], ['U2', 10], ['Metallica', 10]]\n",
      "Error: \n",
      "Retries: 0\n",
      "Total time: 19.1s\n"
     ]
    }
   ],
   "source": [
    "# Cell 18: End-to-End Test — Single Question\n",
    "initial_state = {\n",
    "    \"question\": \"How many albums does each artist have? Show artist name and count, top 5.\",\n",
    "    \"relevant_tables\": [],\n",
    "    \"schema_text\": \"\",\n",
    "    \"generated_sql\": \"\",\n",
    "    \"is_valid\": False,\n",
    "    \"validation_error\": \"\",\n",
    "    \"results\": None,\n",
    "    \"error\": \"\",\n",
    "    \"retry_count\": 0,\n",
    "    \"model_name\": PRIMARY_MODEL,\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Question: {initial_state['question']}\")\n",
    "print(f\"Model: {initial_state['model_name']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "t0 = time.time()\n",
    "final_state = agent.invoke(initial_state)\n",
    "total_time = time.time() - t0\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"FINAL RESULTS\")\n",
    "print(f\"SQL: {final_state['generated_sql']}\")\n",
    "print(f\"Valid: {final_state['is_valid']}\")\n",
    "print(f\"Results: {final_state['results']}\")\n",
    "print(f\"Error: {final_state['error']}\")\n",
    "print(f\"Retries: {final_state['retry_count']}\")\n",
    "print(f\"Total time: {total_time:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04a23d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Q: List all genres\n",
      "Question: List all genres\n",
      "Selected tables (4): ['Genre', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "Schema text length: 523 chars\n",
      "Model: sqlcoder:7b\n",
      "Prompt: sqlcoder\n",
      "Generated SQL: SELECT Genre.Name FROM Genre\n",
      "Latency: 4.9s\n",
      "VALID: SELECT Genre.Name FROM Genre...\n",
      "Executed: SELECT Genre.Name FROM Genre\n",
      "Rows returned: 20\n",
      "  ['Rock']\n",
      "  ['Jazz']\n",
      "  ['Metal']\n",
      "  ['Alternative & Punk']\n",
      "  ['Rock And Roll']\n",
      "  ... (20 rows total)\n",
      "\n",
      "SQL: SELECT Genre.Name FROM Genre\n",
      "Results: [['Rock'], ['Jazz'], ['Metal'], ['Alternative & Punk'], ['Rock And Roll'], ['Blues'], ['Latin'], ['Reggae'], ['Pop'], ['Soundtrack'], ['Bossa Nova'], ['Easy Listening'], ['Heavy Metal'], ['R&B/Soul'], ['Electronica/Dance'], ['World'], ['Hip Hop/Rap'], ['Science Fiction'], ['TV Shows'], ['Sci Fi & Fantasy']]\n",
      "Retries: 0 | Time: 5.0s\n",
      "\n",
      "============================================================\n",
      "Q: What are the top 3 customers by total spending?\n",
      "Question: What are the top 3 customers by total spending?\n",
      "Selected tables (7): ['Customer', 'Invoice', 'Track', 'Employee', 'MediaType', 'Genre', 'Album']\n",
      "Schema text length: 1839 chars\n",
      "Model: sqlcoder:7b\n",
      "Prompt: sqlcoder\n",
      "Generated SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spending FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spending DESC NULLS LAST LIMIT 3\n",
      "Latency: 19.4s\n",
      "VALID: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spending FROM customer p...\n",
      "Execution error: (sqlite3.OperationalError) no such column: p.first_name\n",
      "[SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spending FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spending DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 1: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c\n",
      "Latency: 22.3s\n",
      "VALID: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c...\n",
      "Execution error: (sqlite3.OperationalError) no such column: c.first_name\n",
      "[SQL: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c JOIN invoice i ON c.customerid = i.customerid GROUP BY c.first_name, c.last_name ORDER BY total_spending DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 2: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c\n",
      "Latency: 11.4s\n",
      "VALID: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c...\n",
      "Execution error: (sqlite3.OperationalError) no such column: c.first_name\n",
      "[SQL: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c JOIN invoice i ON c.customerid = i.customerid GROUP BY c.first_name, c.last_name ORDER BY total_spending DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 3: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c\n",
      "Latency: 8.6s\n",
      "VALID: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c...\n",
      "Execution error: (sqlite3.OperationalError) no such column: c.first_name\n",
      "[SQL: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c JOIN invoice i ON c.customerid = i.customerid GROUP BY c.first_name, c.last_name ORDER BY total_spending DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "SQL: SELECT c.first_name, c.last_name, SUM(i.total) AS total_spending FROM customer c JOIN invoice i ON c.customerid = i.customerid GROUP BY c.first_name, c.last_name ORDER BY total_spending DESC NULLS LAST LIMIT 3\n",
      "Results: None\n",
      "Retries: 3 | Time: 62.0s\n",
      "\n",
      "============================================================\n",
      "Q: Find all tracks by AC/DC\n",
      "Question: Find all tracks by AC/DC\n",
      "Selected tables (4): ['Track', 'MediaType', 'Genre', 'Album']\n",
      "Schema text length: 595 chars\n",
      "Model: sqlcoder:7b\n",
      "Prompt: sqlcoder\n",
      "Generated SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER BY Track.TrackId NULLS LAST\n",
      "Latency: 8.3s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ILIKE\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 1: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER\n",
      "Latency: 9.9s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ILIKE\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 2: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER\n",
      "Latency: 4.2s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ILIKE\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 3: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER\n",
      "Latency: 4.3s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ILIKE\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%' ORDER BY Track.TrackId NULLS LAST\n",
      "Results: None\n",
      "Retries: 3 | Time: 27.2s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: End-to-End Test — Multiple Questions\n",
    "test_questions = [\n",
    "    \"List all genres\",\n",
    "    \"What are the top 3 customers by total spending?\",\n",
    "    \"Find all tracks by AC/DC\",\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    state = {\n",
    "        \"question\": q,\n",
    "        \"relevant_tables\": [],\n",
    "        \"schema_text\": \"\",\n",
    "        \"generated_sql\": \"\",\n",
    "        \"is_valid\": False,\n",
    "        \"validation_error\": \"\",\n",
    "        \"results\": None,\n",
    "        \"error\": \"\",\n",
    "        \"retry_count\": 0,\n",
    "        \"model_name\": PRIMARY_MODEL,\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Q: {q}\")\n",
    "    t0 = time.time()\n",
    "    result = agent.invoke(state)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"\\nSQL: {result['generated_sql']}\")\n",
    "    print(f\"Results: {result['results']}\")\n",
    "    print(f\"Retries: {result['retry_count']} | Time: {elapsed:.1f}s\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ade2a2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent recompiled with improved prompts\n",
      "Changes: exact column name rules, LIKE not ILIKE, no NULLS LAST, schema in error repair\n"
     ]
    }
   ],
   "source": [
    "# Cell 20: Improved Prompts — SQLite Rules & Schema in Error Repair\n",
    "GENERIC_PROMPT = \"\"\"You are a SQL expert. Generate a SQLite-compatible SELECT query for the question below.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "Rules:\n",
    "- Return ONLY the SQL query, no explanation\n",
    "- Use only SELECT statements\n",
    "- Use only tables and columns from the schema above\n",
    "- Use exact column names as shown in the schema (case-sensitive)\n",
    "- SQLite syntax only: use LIKE not ILIKE, no NULLS FIRST/LAST\n",
    "- For case-insensitive matching use: LOWER(column) LIKE LOWER('%value%')\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "SQL:\"\"\"\n",
    "\n",
    "SQLCODER_PROMPT = \"\"\"### Task\n",
    "Generate a SQL query to answer the following question:\n",
    "`{question}`\n",
    "\n",
    "### Database Schema\n",
    "{schema_text}\n",
    "\n",
    "### Rules\n",
    "- SQLite dialect only\n",
    "- Use exact column names from schema (case-sensitive: FirstName not first_name)\n",
    "- Use LIKE not ILIKE (SQLite has no ILIKE)\n",
    "- No NULLS FIRST/LAST\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQL query that answers `{question}`:\n",
    "```sql\n",
    "\"\"\"\n",
    "\n",
    "ERROR_REPAIR_GENERIC = \"\"\"The following SQL query produced an error. Fix it using the schema below.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Failed SQL:\n",
    "{generated_sql}\n",
    "\n",
    "Error:\n",
    "{error}\n",
    "\n",
    "Rules:\n",
    "- Use exact column names from the schema above (case-sensitive)\n",
    "- SQLite syntax only: use LIKE not ILIKE\n",
    "- Return ONLY the corrected SQL query, no explanation\n",
    "\n",
    "SQL:\"\"\"\n",
    "\n",
    "ERROR_REPAIR_SQLCODER = \"\"\"### Task\n",
    "The following SQL query produced an error. Fix the query to answer:\n",
    "`{question}`\n",
    "\n",
    "### Database Schema\n",
    "{schema_text}\n",
    "\n",
    "### Failed Query\n",
    "{generated_sql}\n",
    "\n",
    "### Error\n",
    "{error}\n",
    "\n",
    "### Rules\n",
    "- Use exact column names from the schema (case-sensitive: FirstName not first_name)\n",
    "- SQLite dialect only: use LIKE not ILIKE\n",
    "- No NULLS FIRST/LAST\n",
    "\n",
    "### Corrected Answer\n",
    "```sql\n",
    "\"\"\"\n",
    "\n",
    "# Update handle_error to use new templates\n",
    "def handle_error(state: AgentState) -> dict:\n",
    "    \"\"\"Feed error back to LLM for SQL repair.\"\"\"\n",
    "    model = state[\"model_name\"]\n",
    "    \n",
    "    if \"sqlcoder\" in model:\n",
    "        template = ERROR_REPAIR_SQLCODER\n",
    "    else:\n",
    "        template = ERROR_REPAIR_GENERIC\n",
    "    \n",
    "    prompt = template.format(\n",
    "        schema_text=state[\"schema_text\"],\n",
    "        question=state[\"question\"],\n",
    "        generated_sql=state[\"generated_sql\"],\n",
    "        error=state[\"error\"],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOllama(model=model, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    sql = response.content.strip()\n",
    "    sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    sql = sql.rstrip(\";\").strip()\n",
    "    \n",
    "    new_retry = state[\"retry_count\"] + 1\n",
    "    print(f\"Retry {new_retry}: {sql[:80]}\")\n",
    "    print(f\"Latency: {elapsed:.1f}s\")\n",
    "    \n",
    "    return {\"generated_sql\": sql, \"retry_count\": new_retry, \"error\": \"\"}\n",
    "\n",
    "# Also update generate_sql to use new templates\n",
    "def generate_sql(state: AgentState) -> dict:\n",
    "    \"\"\"Generate SQL from question + filtered schema using LLM.\"\"\"\n",
    "    model = state[\"model_name\"]\n",
    "    \n",
    "    if \"sqlcoder\" in model:\n",
    "        template = SQLCODER_PROMPT\n",
    "    else:\n",
    "        template = GENERIC_PROMPT\n",
    "    \n",
    "    prompt = template.format(\n",
    "        schema_text=state[\"schema_text\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOllama(model=model, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    sql = response.content.strip()\n",
    "    sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    sql = sql.rstrip(\";\").strip()\n",
    "    \n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Generated SQL: {sql}\")\n",
    "    print(f\"Latency: {elapsed:.1f}s\")\n",
    "    \n",
    "    return {\"generated_sql\": sql}\n",
    "\n",
    "# Recompile the graph with updated functions\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"schema_filter\", schema_filter)\n",
    "workflow.add_node(\"generate_sql\", generate_sql)\n",
    "workflow.add_node(\"validate_query\", validate_query)\n",
    "workflow.add_node(\"execute_query\", execute_query)\n",
    "workflow.add_node(\"handle_error\", handle_error)\n",
    "workflow.set_entry_point(\"schema_filter\")\n",
    "workflow.add_edge(\"schema_filter\", \"generate_sql\")\n",
    "workflow.add_edge(\"generate_sql\", \"validate_query\")\n",
    "workflow.add_conditional_edges(\"validate_query\", check_validation)\n",
    "workflow.add_conditional_edges(\"execute_query\", should_retry)\n",
    "workflow.add_edge(\"handle_error\", \"validate_query\")\n",
    "agent = workflow.compile()\n",
    "\n",
    "print(\"Agent recompiled with improved prompts\")\n",
    "print(\"Changes: exact column name rules, LIKE not ILIKE, no NULLS LAST, schema in error repair\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65bde600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Q: What are the top 3 customers by total spending?\n",
      "Question: What are the top 3 customers by total spending?\n",
      "Selected tables (7): ['Customer', 'Invoice', 'Track', 'Employee', 'MediaType', 'Genre', 'Album']\n",
      "Schema text length: 1839 chars\n",
      "Model: sqlcoder:7b\n",
      "Generated SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spent DESC NULLS LAST LIMIT 3\n",
      "Latency: 24.2s\n",
      "VALID: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JO...\n",
      "Execution error: (sqlite3.OperationalError) no such column: p.first_name\n",
      "[SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spent DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 1: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JO\n",
      "Latency: 23.5s\n",
      "VALID: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JO...\n",
      "Execution error: (sqlite3.OperationalError) no such column: p.first_name\n",
      "[SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spent DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 2: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JO\n",
      "Latency: 8.5s\n",
      "VALID: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JO...\n",
      "Execution error: (sqlite3.OperationalError) no such column: p.first_name\n",
      "[SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spent DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 3: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JO\n",
      "Latency: 8.3s\n",
      "VALID: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JO...\n",
      "Execution error: (sqlite3.OperationalError) no such column: p.first_name\n",
      "[SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spent DESC NULLS LAST LIMIT 3]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "SQL: SELECT p.first_name, p.last_name, SUM(i.total) AS total_spent FROM customer p JOIN invoice i ON p.customerid = i.customerid GROUP BY p.first_name, p.last_name ORDER BY total_spent DESC NULLS LAST LIMIT 3\n",
      "Results: None\n",
      "Retries: 3 | Time: 64.9s\n",
      "\n",
      "============================================================\n",
      "Q: Find all tracks by AC/DC\n",
      "Question: Find all tracks by AC/DC\n",
      "Selected tables (4): ['Track', 'MediaType', 'Genre', 'Album']\n",
      "Schema text length: 595 chars\n",
      "Model: sqlcoder:7b\n",
      "Generated SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER BY Track.TrackId NULLS LAST\n",
      "Latency: 9.4s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ilike\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 1: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER\n",
      "Latency: 10.0s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ilike\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 2: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER\n",
      "Latency: 4.2s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ilike\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Retry 3: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER\n",
      "Latency: 4.2s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER...\n",
      "Execution error: (sqlite3.OperationalError) near \"ilike\": syntax error\n",
      "[SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER BY Track.TrackId NULLS LAST]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer ilike '%AC/DC%' ORDER BY Track.TrackId NULLS LAST\n",
      "Results: None\n",
      "Retries: 3 | Time: 28.1s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Retest Previously Failed Questions\n",
    "failed_questions = [\n",
    "    \"What are the top 3 customers by total spending?\",\n",
    "    \"Find all tracks by AC/DC\",\n",
    "]\n",
    "\n",
    "for q in failed_questions:\n",
    "    state = {\n",
    "        \"question\": q,\n",
    "        \"relevant_tables\": [],\n",
    "        \"schema_text\": \"\",\n",
    "        \"generated_sql\": \"\",\n",
    "        \"is_valid\": False,\n",
    "        \"validation_error\": \"\",\n",
    "        \"results\": None,\n",
    "        \"error\": \"\",\n",
    "        \"retry_count\": 0,\n",
    "        \"model_name\": PRIMARY_MODEL,\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Q: {q}\")\n",
    "    t0 = time.time()\n",
    "    result = agent.invoke(state)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"\\nSQL: {result['generated_sql']}\")\n",
    "    print(f\"Results: {result['results']}\")\n",
    "    print(f\"Retries: {result['retry_count']} | Time: {elapsed:.1f}s\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90588649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input:  SELECT p.first_name, p.last_name FROM customer p ORDER BY p.last_name NULLS LAST\n",
      "  Post-processed: removed NULLS FIRST/LAST, fixed column casing\n",
      "  Output: SELECT p.first_name, p.last_name FROM Customer p ORDER BY p.last_name\n",
      "\n",
      "  Input:  SELECT Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%'\n",
      "  Post-processed: ILIKE->LIKE, fixed column casing\n",
      "  Output: SELECT Track.Name FROM Track WHERE Composer LIKE '%AC/DC%'\n",
      "\n",
      "  Input:  SELECT Name FROM Artist LIMIT 5\n",
      "  Output: SELECT Name FROM Artist LIMIT 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 22: SQL Post-Processing for SQLite Compatibility\n",
    "import re\n",
    "\n",
    "def build_column_map():\n",
    "    \"\"\"Build case-insensitive column name mapping from schema_info.\"\"\"\n",
    "    col_map = {}  # lowercase -> actual name\n",
    "    for table_name, info in schema_info.items():\n",
    "        for col in info[\"columns\"]:\n",
    "            col_map[col[\"name\"].lower()] = col[\"name\"]\n",
    "        # Also map table names\n",
    "        col_map[table_name.lower()] = table_name\n",
    "    return col_map\n",
    "\n",
    "COLUMN_MAP = build_column_map()\n",
    "\n",
    "def postprocess_sql(sql: str) -> str:\n",
    "    \"\"\"Fix known SQLite incompatibilities in generated SQL.\"\"\"\n",
    "    original = sql\n",
    "    \n",
    "    # 1. Replace ILIKE with LIKE (SQLite LIKE is case-insensitive for ASCII)\n",
    "    sql = re.sub(r'\\bILIKE\\b', 'LIKE', sql, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 2. Remove NULLS FIRST / NULLS LAST\n",
    "    sql = re.sub(r'\\s+NULLS\\s+(FIRST|LAST)\\b', '', sql, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 3. Fix column name casing (snake_case -> PascalCase)\n",
    "    def replace_identifier(match):\n",
    "        word = match.group(0)\n",
    "        # Don't replace SQL keywords or aliases\n",
    "        sql_keywords = {\n",
    "            'SELECT', 'FROM', 'WHERE', 'JOIN', 'ON', 'GROUP', 'BY', 'ORDER',\n",
    "            'HAVING', 'LIMIT', 'AS', 'AND', 'OR', 'NOT', 'IN', 'LIKE', 'IS',\n",
    "            'NULL', 'COUNT', 'SUM', 'AVG', 'MIN', 'MAX', 'DESC', 'ASC',\n",
    "            'DISTINCT', 'BETWEEN', 'CASE', 'WHEN', 'THEN', 'ELSE', 'END',\n",
    "            'INNER', 'LEFT', 'RIGHT', 'OUTER', 'UNION', 'ALL', 'EXISTS',\n",
    "            'CAST', 'LOWER', 'UPPER', 'LENGTH', 'SUBSTR', 'TRIM',\n",
    "        }\n",
    "        if word.upper() in sql_keywords:\n",
    "            return word\n",
    "        lookup = word.lower().replace('\"', '').replace(\"'\", '')\n",
    "        if lookup in COLUMN_MAP:\n",
    "            return COLUMN_MAP[lookup]\n",
    "        return word\n",
    "    \n",
    "    # Match identifiers (possibly quoted)\n",
    "    sql = re.sub(r'\"?\\b[A-Za-z_]\\w*\\b\"?', replace_identifier, sql)\n",
    "    \n",
    "    if sql != original:\n",
    "        changes = []\n",
    "        if 'ILIKE' in original.upper() and 'ILIKE' not in sql.upper():\n",
    "            changes.append(\"ILIKE->LIKE\")\n",
    "        if re.search(r'NULLS\\s+(FIRST|LAST)', original, re.IGNORECASE):\n",
    "            changes.append(\"removed NULLS FIRST/LAST\")\n",
    "        if sql.lower() != original.lower():\n",
    "            changes.append(\"fixed column casing\")\n",
    "        print(f\"  Post-processed: {', '.join(changes)}\")\n",
    "    \n",
    "    return sql\n",
    "\n",
    "# Test it\n",
    "test_cases = [\n",
    "    \"SELECT p.first_name, p.last_name FROM customer p ORDER BY p.last_name NULLS LAST\",\n",
    "    \"SELECT Track.Name FROM Track WHERE Composer ILIKE '%AC/DC%'\",\n",
    "    \"SELECT Name FROM Artist LIMIT 5\",  # should be unchanged\n",
    "]\n",
    "\n",
    "for sql in test_cases:\n",
    "    print(f\"  Input:  {sql}\")\n",
    "    fixed = postprocess_sql(sql)\n",
    "    print(f\"  Output: {fixed}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88efbe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key mappings:\n",
      "  first_name           -> FirstName\n",
      "  firstname            -> FirstName\n",
      "  last_name            -> LastName\n",
      "  lastname             -> LastName\n",
      "  customerid           -> CustomerId\n",
      "  customer_id          -> CustomerId\n",
      "  artistid             -> ArtistId\n",
      "  artist_id            -> ArtistId\n",
      "  supportrepid         -> SupportRepId\n",
      "  support_rep_id       -> SupportRepId\n",
      "  billingcountry       -> BillingCountry\n",
      "  billing_country      -> BillingCountry\n",
      "\n",
      "Post-process test:\n",
      "  Input:  SELECT p.first_name, p.last_name FROM customer p ORDER BY p.last_name NULLS LAST\n",
      "  Post-processed: removed NULLS FIRST/LAST, fixed column casing\n",
      "  Output: SELECT p.FirstName, p.LastName FROM Customer p ORDER BY p.LastName\n"
     ]
    }
   ],
   "source": [
    "# Cell 23: Fix Column Mapping — Handle snake_case to PascalCase\n",
    "def build_column_map():\n",
    "    \"\"\"Build case-insensitive column name mapping, including snake_case variants.\"\"\"\n",
    "    col_map = {}\n",
    "    for table_name, info in schema_info.items():\n",
    "        for col in info[\"columns\"]:\n",
    "            actual = col[\"name\"]\n",
    "            # Map lowercase version\n",
    "            col_map[actual.lower()] = actual\n",
    "            # Map snake_case version (e.g., first_name -> FirstName)\n",
    "            snake = re.sub(r'(?<!^)(?=[A-Z])', '_', actual).lower()\n",
    "            col_map[snake] = actual\n",
    "        # Table names\n",
    "        col_map[table_name.lower()] = table_name\n",
    "    return col_map\n",
    "\n",
    "COLUMN_MAP = build_column_map()\n",
    "\n",
    "# Verify the fix\n",
    "print(\"Key mappings:\")\n",
    "for key in [\"first_name\", \"firstname\", \"last_name\", \"lastname\", \n",
    "            \"customerid\", \"customer_id\", \"artistid\", \"artist_id\",\n",
    "            \"supportrepid\", \"support_rep_id\", \"billingcountry\", \"billing_country\"]:\n",
    "    actual = COLUMN_MAP.get(key, \"NOT FOUND\")\n",
    "    print(f\"  {key:20s} -> {actual}\")\n",
    "\n",
    "# Retest postprocess\n",
    "print(\"\\nPost-process test:\")\n",
    "sql = \"SELECT p.first_name, p.last_name FROM customer p ORDER BY p.last_name NULLS LAST\"\n",
    "print(f\"  Input:  {sql}\")\n",
    "print(f\"  Output: {postprocess_sql(sql)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2cef87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Q: What are the top 3 customers by total spending?\n",
      "Question: What are the top 3 customers by total spending?\n",
      "Selected tables (7): ['Customer', 'Invoice', 'Track', 'Employee', 'MediaType', 'Genre', 'Album']\n",
      "Schema text length: 1839 chars\n",
      "  Post-processed: removed NULLS FIRST/LAST, fixed column casing\n",
      "Model: sqlcoder:7b\n",
      "Generated SQL: SELECT p.FirstName, p.LastName, SUM(i.Total) AS total_spent FROM Customer p JOIN Invoice i ON p.CustomerId = i.CustomerId GROUP BY p.FirstName, p.LastName ORDER BY total_spent DESC LIMIT 3\n",
      "Latency: 20.7s\n",
      "VALID: SELECT p.FirstName, p.LastName, SUM(i.Total) AS total_spent FROM Customer p JOIN...\n",
      "Executed: SELECT p.FirstName, p.LastName, SUM(i.Total) AS total_spent FROM Customer p JOIN\n",
      "Rows returned: 3\n",
      "  ['Helena', 'Holý', 49.620000000000005]\n",
      "  ['Richard', 'Cunningham', 47.620000000000005]\n",
      "  ['Luis', 'Rojas', 46.62]\n",
      "\n",
      "SQL: SELECT p.FirstName, p.LastName, SUM(i.Total) AS total_spent FROM Customer p JOIN Invoice i ON p.CustomerId = i.CustomerId GROUP BY p.FirstName, p.LastName ORDER BY total_spent DESC LIMIT 3\n",
      "Results: [['Helena', 'Holý', 49.620000000000005], ['Richard', 'Cunningham', 47.620000000000005], ['Luis', 'Rojas', 46.62]]\n",
      "Retries: 0 | Time: 20.8s\n",
      "\n",
      "============================================================\n",
      "Q: Find all tracks by AC/DC\n",
      "Question: Find all tracks by AC/DC\n",
      "Selected tables (4): ['Track', 'MediaType', 'Genre', 'Album']\n",
      "Schema text length: 595 chars\n",
      "  Post-processed: ILIKE->LIKE, removed NULLS FIRST/LAST, fixed column casing\n",
      "Model: sqlcoder:7b\n",
      "Generated SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer LIKE '%AC/DC%' ORDER BY Track.TrackId\n",
      "Latency: 8.0s\n",
      "VALID: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer LIKE '%AC/DC%' ORDER ...\n",
      "Executed: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer LIKE '%AC/DC%' ORDER \n",
      "Rows returned: 8\n",
      "  [15, 'Go Down']\n",
      "  [16, 'Dog Eat Dog']\n",
      "  [17, 'Let There Be Rock']\n",
      "  [18, 'Bad Boy Boogie']\n",
      "  [19, 'Problem Child']\n",
      "  ... (8 rows total)\n",
      "\n",
      "SQL: SELECT Track.TrackId, Track.Name FROM Track WHERE Composer LIKE '%AC/DC%' ORDER BY Track.TrackId\n",
      "Results: [[15, 'Go Down'], [16, 'Dog Eat Dog'], [17, 'Let There Be Rock'], [18, 'Bad Boy Boogie'], [19, 'Problem Child'], [20, 'Overdose'], [21, \"Hell Ain't A Bad Place To Be\"], [22, 'Whole Lotta Rosie']]\n",
      "Retries: 0 | Time: 8.1s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 24: Integrate Post-Processing & Retest Failed Queries\n",
    "def generate_sql(state: AgentState) -> dict:\n",
    "    \"\"\"Generate SQL from question + filtered schema using LLM, with post-processing.\"\"\"\n",
    "    model = state[\"model_name\"]\n",
    "    \n",
    "    if \"sqlcoder\" in model:\n",
    "        template = SQLCODER_PROMPT\n",
    "    else:\n",
    "        template = GENERIC_PROMPT\n",
    "    \n",
    "    prompt = template.format(\n",
    "        schema_text=state[\"schema_text\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOllama(model=model, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    sql = response.content.strip()\n",
    "    sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    sql = sql.rstrip(\";\").strip()\n",
    "    \n",
    "    # Post-process for SQLite compatibility\n",
    "    sql = postprocess_sql(sql)\n",
    "    \n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Generated SQL: {sql}\")\n",
    "    print(f\"Latency: {elapsed:.1f}s\")\n",
    "    \n",
    "    return {\"generated_sql\": sql}\n",
    "\n",
    "# Also apply post-processing in handle_error\n",
    "def handle_error(state: AgentState) -> dict:\n",
    "    \"\"\"Feed error back to LLM for SQL repair, with post-processing.\"\"\"\n",
    "    model = state[\"model_name\"]\n",
    "    \n",
    "    if \"sqlcoder\" in model:\n",
    "        template = ERROR_REPAIR_SQLCODER\n",
    "    else:\n",
    "        template = ERROR_REPAIR_GENERIC\n",
    "    \n",
    "    prompt = template.format(\n",
    "        schema_text=state[\"schema_text\"],\n",
    "        question=state[\"question\"],\n",
    "        generated_sql=state[\"generated_sql\"],\n",
    "        error=state[\"error\"],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOllama(model=model, base_url=OLLAMA_BASE_URL, temperature=0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    sql = response.content.strip()\n",
    "    sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    sql = sql.rstrip(\";\").strip()\n",
    "    sql = postprocess_sql(sql)\n",
    "    \n",
    "    new_retry = state[\"retry_count\"] + 1\n",
    "    print(f\"Retry {new_retry}: {sql[:80]}\")\n",
    "    print(f\"Latency: {elapsed:.1f}s\")\n",
    "    \n",
    "    return {\"generated_sql\": sql, \"retry_count\": new_retry, \"error\": \"\"}\n",
    "\n",
    "# Recompile\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"schema_filter\", schema_filter)\n",
    "workflow.add_node(\"generate_sql\", generate_sql)\n",
    "workflow.add_node(\"validate_query\", validate_query)\n",
    "workflow.add_node(\"execute_query\", execute_query)\n",
    "workflow.add_node(\"handle_error\", handle_error)\n",
    "workflow.set_entry_point(\"schema_filter\")\n",
    "workflow.add_edge(\"schema_filter\", \"generate_sql\")\n",
    "workflow.add_edge(\"generate_sql\", \"validate_query\")\n",
    "workflow.add_conditional_edges(\"validate_query\", check_validation)\n",
    "workflow.add_conditional_edges(\"execute_query\", should_retry)\n",
    "workflow.add_edge(\"handle_error\", \"validate_query\")\n",
    "agent = workflow.compile()\n",
    "\n",
    "# Retest the two failed queries\n",
    "for q in [\"What are the top 3 customers by total spending?\", \"Find all tracks by AC/DC\"]:\n",
    "    state = {\n",
    "        \"question\": q, \"relevant_tables\": [], \"schema_text\": \"\",\n",
    "        \"generated_sql\": \"\", \"is_valid\": False, \"validation_error\": \"\",\n",
    "        \"results\": None, \"error\": \"\", \"retry_count\": 0, \"model_name\": PRIMARY_MODEL,\n",
    "    }\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Q: {q}\")\n",
    "    t0 = time.time()\n",
    "    result = agent.invoke(state)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"\\nSQL: {result['generated_sql']}\")\n",
    "    print(f\"Results: {result['results']}\")\n",
    "    print(f\"Retries: {result['retry_count']} | Time: {elapsed:.1f}s\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14fe90b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Q: How many tracks are in the Heavy Metal, Metal, and Blues genres?\n",
      "Question: How many tracks are in the Heavy Metal, Metal, and Blues genres?\n",
      "Selected tables (7): ['Invoice', 'Genre', 'Track', 'InvoiceLine', 'Customer', 'MediaType', 'Album']\n",
      "Schema text length: 1664 chars\n",
      "  Post-processed: ILIKE->LIKE, fixed column casing\n",
      "Model: sqlcoder:7b\n",
      "Generated SQL: SELECT COUNT(*) AS total_tracks FROM Track WHERE GenreId IN (SELECT GenreId FROM Genre WHERE Name LIKE '%heavy%metal%' OR Name LIKE '%metal%' OR Name LIKE '%blues%')\n",
      "Latency: 17.9s\n",
      "VALID: SELECT COUNT(*) AS total_tracks FROM Track WHERE GenreId IN (SELECT GenreId FROM...\n",
      "Executed: SELECT COUNT(*) AS total_tracks FROM Track WHERE GenreId IN (SELECT GenreId FROM\n",
      "Rows returned: 1\n",
      "  [483]\n",
      "\n",
      "SQL: SELECT COUNT(*) AS total_tracks FROM Track WHERE GenreId IN (SELECT GenreId FROM Genre WHERE Name LIKE '%heavy%metal%' OR Name LIKE '%metal%' OR Name LIKE '%blues%')\n",
      "Results: [[483]]\n",
      "Retries: 0 | Time: 18.0s\n",
      "\n",
      "============================================================\n",
      "Q: Who are the top 5 artists with the most tracks in Heavy Metal, Metal, or Blues genres?\n",
      "Question: Who are the top 5 artists with the most tracks in Heavy Metal, Metal, or Blues genres?\n",
      "Selected tables (8): ['Invoice', 'Artist', 'Genre', 'Track', 'InvoiceLine', 'Customer', 'MediaType', 'Album']\n",
      "Schema text length: 1748 chars\n",
      "  Post-processed: removed NULLS FIRST/LAST, fixed column casing\n",
      "Model: sqlcoder:7b\n",
      "Generated SQL: SELECT a.Name AS artist_name, COUNT(t.TrackId) AS total_tracks FROM Artist a JOIN Album al ON a.ArtistId = al.ArtistId JOIN Track t ON al.AlbumId = t.AlbumId WHERE t.MediaTypeId IN (1, 2, 3) AND EXISTS (SELECT 1 FROM Genre g WHERE g.GenreId = t.GenreId AND g.Name IN ('Heavy Metal', 'Metal', 'Blues')) GROUP BY a.Name ORDER BY total_tracks DESC LIMIT 5\n",
      "Latency: 26.9s\n",
      "VALID: SELECT a.Name AS artist_name, COUNT(t.TrackId) AS total_tracks FROM Artist a JOI...\n",
      "Executed: SELECT a.Name AS artist_name, COUNT(t.TrackId) AS total_tracks FROM Artist a JOI\n",
      "Rows returned: 5\n",
      "  ['Iron Maiden', 132]\n",
      "  ['Metallica', 112]\n",
      "  ['Eric Clapton', 32]\n",
      "  ['The Black Crowes', 19]\n",
      "  ['Black Label Society', 18]\n",
      "\n",
      "SQL: SELECT a.Name AS artist_name, COUNT(t.TrackId) AS total_tracks FROM Artist a JOIN Album al ON a.ArtistId = al.ArtistId JOIN Track t ON al.AlbumId = t.AlbumId WHERE t.MediaTypeId IN (1, 2, 3) AND EXISTS (SELECT 1 FROM Genre g WHERE g.GenreId = t.GenreId AND g.Name IN ('Heavy Metal', 'Metal', 'Blues')) GROUP BY a.Name ORDER BY total_tracks DESC LIMIT 5\n",
      "Results: [['Iron Maiden', 132], ['Metallica', 112], ['Eric Clapton', 32], ['The Black Crowes', 19], ['Black Label Society', 18]]\n",
      "Retries: 0 | Time: 27.0s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 25: Genre Exploration — Heavy Metal, Metal & Blues\n",
    "genre_questions = [\n",
    "    \"How many tracks are in the Heavy Metal, Metal, and Blues genres?\",\n",
    "    \"Who are the top 5 artists with the most tracks in Heavy Metal, Metal, or Blues genres?\",\n",
    "]\n",
    "\n",
    "for q in genre_questions:\n",
    "    state = {\n",
    "        \"question\": q, \"relevant_tables\": [], \"schema_text\": \"\",\n",
    "        \"generated_sql\": \"\", \"is_valid\": False, \"validation_error\": \"\",\n",
    "        \"results\": None, \"error\": \"\", \"retry_count\": 0, \"model_name\": PRIMARY_MODEL,\n",
    "    }\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Q: {q}\")\n",
    "    t0 = time.time()\n",
    "    result = agent.invoke(state)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"\\nSQL: {result['generated_sql']}\")\n",
    "    print(f\"Results: {result['results']}\")\n",
    "    print(f\"Retries: {result['retry_count']} | Time: {elapsed:.1f}s\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c5dd2",
   "metadata": {},
   "source": [
    "## Phase 3: Evaluation Framework (EXP-001)\n",
    "\n",
    "**Experiment:** EXP-001 — Text-to-SQL Model Comparison\n",
    "**DSM Framework:** C.1.3 (Capability Experiment), C.1.5 (Limitation Discovery), C.1.6 (Artifact Organization)\n",
    "**Artifacts:** `data/experiments/s01_d02_exp001/`\n",
    "\n",
    "**Objective:** Compare `sqlcoder:7b` (SQL fine-tune) vs `llama3.1:8b` (general-purpose) on 14 curated queries across Easy/Medium/Hard difficulties.\n",
    "\n",
    "**Hypotheses:**\n",
    "1. sqlcoder:7b achieves higher Execution Accuracy (SQL fine-tuning advantage)\n",
    "2. llama3.1:8b produces more readable SQL (JOINs for names) but slower\n",
    "3. sqlcoder:7b requires post-processing more frequently (PostgreSQL dialect bias)\n",
    "\n",
    "**Metrics:** Execution Accuracy, Raw/Effective Parsability, Retry Rate, Post-Processing Rate, Latency, Error Categories\n",
    "\n",
    "**Plan:**\n",
    "- Cell 27: Test suite definition (14 queries + ground truth)\n",
    "- Cell 28: Evaluation harness (run agent, capture all metrics)\n",
    "- Cell 29: Run — sqlcoder:7b\n",
    "- Cell 30: Run — llama3.1:8b\n",
    "- Cell 31: Results analysis\n",
    "- Cell 32: Findings + limitations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1037553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test suite: 14 queries\n",
      "  Easy: 5\n",
      "  Medium: 5\n",
      "  Hard: 4\n",
      "\n",
      "  [E1] Easy   | How many employees are there?                           | GT: 8\n",
      "  [E2] Easy   | List all media types                                    | GT: 5\n",
      "  [E3] Easy   | What is the most expensive track?                       | GT: ('Battlestar Galactica: The Story So Far', 1.99)\n",
      "  [E4] Easy   | How many customers are from Brazil?                     | GT: 5\n",
      "  [E5] Easy   | Show the 5 longest tracks by duration                   | GT: 5 rows: [['Occupation / Precipice', 5286953], ['Through a Lo\n",
      "  [M1] Medium | Which genre has the most tracks?                        | GT: ('Rock', 1297)\n",
      "  [M2] Medium | How much has each customer spent in total? Show top 5.  | GT: 5 rows: [['Helena', 'Holý', 49.620000000000005], ['Richard',\n",
      "  [M3] Medium | List albums that have more than 20 tracks               | GT: 17 rows: [['Greatest Hits', 57], ['Minha Historia', 34]]...\n",
      "  [M4] Medium | Which employees support the most customers?             | GT: 3 rows: [['Jane', 'Peacock', 21], ['Margaret', 'Park', 20]].\n",
      "  [M5] Medium | What are the top 3 best-selling genres by revenue?      | GT: 3 rows: [['Rock', 826.6500000000061], ['Latin', 382.14000000\n",
      "  [H1] Hard   | Which artists have tracks in more than 2 genres?        | GT: 7 rows: [['Iron Maiden', 4], ['Battlestar Galactica', 3]]...\n",
      "  [H2] Hard   | Find customers who have never purchased a Jazz track    | GT: 27\n",
      "  [H3] Hard   | What is the average invoice total by country, only for  | GT: 2 rows: [['USA', 5.747912087912091, 13], ['Canada', 5.427857\n",
      "  [H4] Hard   | List the top 3 playlists by total track duration in hou | GT: 3 rows: [['Music', 243.8008563888889], ['Music', 243.8008563\n"
     ]
    }
   ],
   "source": [
    "# Cell 27: EXP-001 Test Suite & Evaluation Setup\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class TestQuery:\n",
    "    id: str\n",
    "    difficulty: str  # Easy, Medium, Hard\n",
    "    question: str\n",
    "    expected_description: str  # What correct results look like\n",
    "    expected_tables: list[str] = field(default_factory=list)  # Minimum tables needed\n",
    "\n",
    "TEST_SUITE = [\n",
    "    # --- Easy (5): single table, simple WHERE, basic aggregation ---\n",
    "    TestQuery(\"E1\", \"Easy\", \"How many employees are there?\",\n",
    "             \"Single number: 8\", [\"Employee\"]),\n",
    "    TestQuery(\"E2\", \"Easy\", \"List all media types\",\n",
    "             \"5 types returned\", [\"MediaType\"]),\n",
    "    TestQuery(\"E3\", \"Easy\", \"What is the most expensive track?\",\n",
    "             \"Track with max UnitPrice\", [\"Track\"]),\n",
    "    TestQuery(\"E4\", \"Easy\", \"How many customers are from Brazil?\",\n",
    "             \"Single count of Brazilian customers\", [\"Customer\"]),\n",
    "    TestQuery(\"E5\", \"Easy\", \"Show the 5 longest tracks by duration\",\n",
    "             \"5 tracks ordered by Milliseconds DESC\", [\"Track\"]),\n",
    "\n",
    "    # --- Medium (5): JOINs, GROUP BY + HAVING, ORDER BY + LIMIT ---\n",
    "    TestQuery(\"M1\", \"Medium\", \"Which genre has the most tracks?\",\n",
    "             \"Rock with 1,297 tracks\", [\"Track\", \"Genre\"]),\n",
    "    TestQuery(\"M2\", \"Medium\", \"How much has each customer spent in total? Show top 5.\",\n",
    "             \"Top 5 customers by SUM(Invoice.Total)\", [\"Customer\", \"Invoice\"]),\n",
    "    TestQuery(\"M3\", \"Medium\", \"List albums that have more than 20 tracks\",\n",
    "             \"Albums with track count > 20\", [\"Album\", \"Track\"]),\n",
    "    TestQuery(\"M4\", \"Medium\", \"Which employees support the most customers?\",\n",
    "             \"Employees ranked by customer count\", [\"Employee\", \"Customer\"]),\n",
    "    TestQuery(\"M5\", \"Medium\", \"What are the top 3 best-selling genres by revenue?\",\n",
    "             \"Genres by SUM(UnitPrice * Quantity) from InvoiceLine\",\n",
    "             [\"Genre\", \"Track\", \"InvoiceLine\"]),\n",
    "\n",
    "    # --- Hard (4): multi-table JOINs, subqueries, complex aggregation ---\n",
    "    TestQuery(\"H1\", \"Hard\", \"Which artists have tracks in more than 2 genres?\",\n",
    "             \"Artists with genre count > 2\",\n",
    "             [\"Artist\", \"Album\", \"Track\", \"Genre\"]),\n",
    "    TestQuery(\"H2\", \"Hard\",\n",
    "             \"Find customers who have never purchased a Jazz track\",\n",
    "             \"Customers NOT IN Jazz purchases\",\n",
    "             [\"Customer\", \"Invoice\", \"InvoiceLine\", \"Track\", \"Genre\"]),\n",
    "    TestQuery(\"H3\", \"Hard\",\n",
    "             \"What is the average invoice total by country, only for countries with more than 5 customers?\",\n",
    "             \"Countries with >5 customers showing AVG(Total)\",\n",
    "             [\"Customer\", \"Invoice\"]),\n",
    "    TestQuery(\"H4\", \"Hard\",\n",
    "             \"List the top 3 playlists by total track duration in hours\",\n",
    "             \"Playlists by SUM(Milliseconds)/3600000\",\n",
    "             [\"Playlist\", \"PlaylistTrack\", \"Track\"]),\n",
    "]\n",
    "\n",
    "# Compute ground truth by running known-correct SQL\n",
    "GROUND_TRUTH = {}\n",
    "with engine.connect() as conn:\n",
    "    GROUND_TRUTH[\"E1\"] = conn.execute(text(\"SELECT COUNT(*) FROM Employee\")).scalar()\n",
    "    GROUND_TRUTH[\"E2\"] = conn.execute(text(\"SELECT COUNT(*) FROM MediaType\")).scalar()\n",
    "    GROUND_TRUTH[\"E3\"] = conn.execute(text(\n",
    "        \"SELECT Name, UnitPrice FROM Track ORDER BY UnitPrice DESC LIMIT 1\"\n",
    "    )).fetchone()\n",
    "    GROUND_TRUTH[\"E4\"] = conn.execute(text(\n",
    "        \"SELECT COUNT(*) FROM Customer WHERE Country = 'Brazil'\"\n",
    "    )).scalar()\n",
    "    GROUND_TRUTH[\"E5\"] = conn.execute(text(\n",
    "        \"SELECT Name, Milliseconds FROM Track ORDER BY Milliseconds DESC LIMIT 5\"\n",
    "    )).fetchall()\n",
    "    GROUND_TRUTH[\"M1\"] = conn.execute(text(\n",
    "        \"SELECT g.Name, COUNT(t.TrackId) as cnt FROM Genre g \"\n",
    "        \"JOIN Track t ON g.GenreId = t.GenreId \"\n",
    "        \"GROUP BY g.Name ORDER BY cnt DESC LIMIT 1\"\n",
    "    )).fetchone()\n",
    "    GROUND_TRUTH[\"M2\"] = conn.execute(text(\n",
    "        \"SELECT c.FirstName, c.LastName, SUM(i.Total) as total \"\n",
    "        \"FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId \"\n",
    "        \"GROUP BY c.CustomerId ORDER BY total DESC LIMIT 5\"\n",
    "    )).fetchall()\n",
    "    GROUND_TRUTH[\"M3\"] = conn.execute(text(\n",
    "        \"SELECT a.Title, COUNT(t.TrackId) as cnt FROM Album a \"\n",
    "        \"JOIN Track t ON a.AlbumId = t.AlbumId \"\n",
    "        \"GROUP BY a.AlbumId HAVING cnt > 20 ORDER BY cnt DESC\"\n",
    "    )).fetchall()\n",
    "    GROUND_TRUTH[\"M4\"] = conn.execute(text(\n",
    "        \"SELECT e.FirstName, e.LastName, COUNT(c.CustomerId) as cnt \"\n",
    "        \"FROM Employee e JOIN Customer c ON e.EmployeeId = c.SupportRepId \"\n",
    "        \"GROUP BY e.EmployeeId ORDER BY cnt DESC\"\n",
    "    )).fetchall()\n",
    "    GROUND_TRUTH[\"M5\"] = conn.execute(text(\n",
    "        \"SELECT g.Name, SUM(il.UnitPrice * il.Quantity) as revenue \"\n",
    "        \"FROM Genre g JOIN Track t ON g.GenreId = t.GenreId \"\n",
    "        \"JOIN InvoiceLine il ON t.TrackId = il.TrackId \"\n",
    "        \"GROUP BY g.Name ORDER BY revenue DESC LIMIT 3\"\n",
    "    )).fetchall()\n",
    "    GROUND_TRUTH[\"H1\"] = conn.execute(text(\n",
    "        \"SELECT ar.Name, COUNT(DISTINCT g.GenreId) as genre_count \"\n",
    "        \"FROM Artist ar JOIN Album al ON ar.ArtistId = al.ArtistId \"\n",
    "        \"JOIN Track t ON al.AlbumId = t.AlbumId \"\n",
    "        \"JOIN Genre g ON t.GenreId = g.GenreId \"\n",
    "        \"GROUP BY ar.ArtistId HAVING genre_count > 2 ORDER BY genre_count DESC\"\n",
    "    )).fetchall()\n",
    "    GROUND_TRUTH[\"H2\"] = conn.execute(text(\n",
    "        \"SELECT COUNT(*) FROM Customer WHERE CustomerId NOT IN (\"\n",
    "        \"SELECT DISTINCT c.CustomerId FROM Customer c \"\n",
    "        \"JOIN Invoice i ON c.CustomerId = i.CustomerId \"\n",
    "        \"JOIN InvoiceLine il ON i.InvoiceId = il.InvoiceId \"\n",
    "        \"JOIN Track t ON il.TrackId = t.TrackId \"\n",
    "        \"JOIN Genre g ON t.GenreId = g.GenreId \"\n",
    "        \"WHERE g.Name = 'Jazz')\"\n",
    "    )).scalar()\n",
    "    GROUND_TRUTH[\"H3\"] = conn.execute(text(\n",
    "        \"SELECT c.Country, AVG(i.Total) as avg_total, COUNT(DISTINCT c.CustomerId) as cust_count \"\n",
    "        \"FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId \"\n",
    "        \"GROUP BY c.Country HAVING cust_count > 5 ORDER BY avg_total DESC\"\n",
    "    )).fetchall()\n",
    "    GROUND_TRUTH[\"H4\"] = conn.execute(text(\n",
    "        \"SELECT p.Name, SUM(t.Milliseconds) / 3600000.0 as hours \"\n",
    "        \"FROM Playlist p JOIN PlaylistTrack pt ON p.PlaylistId = pt.PlaylistId \"\n",
    "        \"JOIN Track t ON pt.TrackId = t.TrackId \"\n",
    "        \"GROUP BY p.PlaylistId ORDER BY hours DESC LIMIT 3\"\n",
    "    )).fetchall()\n",
    "\n",
    "# Display test suite and ground truth\n",
    "print(f\"Test suite: {len(TEST_SUITE)} queries\")\n",
    "print(f\"  Easy: {sum(1 for t in TEST_SUITE if t.difficulty == 'Easy')}\")\n",
    "print(f\"  Medium: {sum(1 for t in TEST_SUITE if t.difficulty == 'Medium')}\")\n",
    "print(f\"  Hard: {sum(1 for t in TEST_SUITE if t.difficulty == 'Hard')}\")\n",
    "print()\n",
    "for tq in TEST_SUITE:\n",
    "    gt = GROUND_TRUTH[tq.id]\n",
    "    if isinstance(gt, (int, float)):\n",
    "        gt_display = str(gt)\n",
    "    elif isinstance(gt, tuple):\n",
    "        gt_display = str(list(gt))\n",
    "    elif isinstance(gt, list):\n",
    "        gt_display = f\"{len(gt)} rows: {[list(r) for r in gt[:2]]}...\"\n",
    "    else:\n",
    "        gt_display = str(gt)\n",
    "    print(f\"  [{tq.id}] {tq.difficulty:6s} | {tq.question[:55]:55s} | GT: {gt_display[:60]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc28eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation harness defined.\n",
      "Next steps:\n",
      "  Cell 29 → sqlcoder_results = run_evaluation('sqlcoder:7b', TEST_SUITE, GROUND_TRUTH)\n",
      "  Cell 30 → llama_results   = run_evaluation('llama3.1:8b', TEST_SUITE, GROUND_TRUTH)\n"
     ]
    }
   ],
   "source": [
    "# Cell 28: EXP-001 Evaluation Harness\n",
    "\n",
    "import time\n",
    "import sqlglot\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional\n",
    "\n",
    "@dataclass\n",
    "class EvalResult:\n",
    "    \"\"\"Single query evaluation result for EXP-001.\"\"\"\n",
    "    query_id: str\n",
    "    difficulty: str\n",
    "    question: str\n",
    "    model: str\n",
    "    raw_sql: Optional[str] = None\n",
    "    final_sql: Optional[str] = None\n",
    "    raw_parsable: bool = False\n",
    "    effectively_parsable: bool = False\n",
    "    execution_accurate: bool = False\n",
    "    post_processing_applied: bool = False\n",
    "    retry_count: int = 0\n",
    "    latency_seconds: float = 0.0\n",
    "    actual_result: Any = None\n",
    "    error: Optional[str] = None\n",
    "    error_category: Optional[str] = None\n",
    "\n",
    "def check_sql_parsable(sql: str) -> bool:\n",
    "    \"\"\"Check if SQL parses with sqlglot.\"\"\"\n",
    "    if not sql or not sql.strip():\n",
    "        return False\n",
    "    try:\n",
    "        result = sqlglot.parse(sql)\n",
    "        return len(result) > 0 and result[0] is not None\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def to_plain(val):\n",
    "    \"\"\"Convert SQLAlchemy Row objects to plain Python types.\"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    if hasattr(val, '_mapping'):\n",
    "        return tuple(val)\n",
    "    if isinstance(val, list):\n",
    "        return [to_plain(v) for v in val]\n",
    "    if isinstance(val, tuple):\n",
    "        return tuple(to_plain(v) for v in val)\n",
    "    return val\n",
    "\n",
    "def values_match(a, e) -> bool:\n",
    "    \"\"\"Compare two values with float tolerance.\"\"\"\n",
    "    if isinstance(a, float) and isinstance(e, float):\n",
    "        return abs(a - e) < 0.01\n",
    "    return a == e\n",
    "\n",
    "def compare_results(actual, expected, query_id: str) -> bool:\n",
    "    \"\"\"Compare agent output to ground truth.\n",
    "    \n",
    "    GT formats:\n",
    "    - Scalar int/float: count queries (E1, E4) or row-count checks (E2, H2)\n",
    "    - Tuple: single-row result (E3, M1)  \n",
    "    - List: multi-row result (E5, M2-M5, H1, H3, H4)\n",
    "    \n",
    "    For scalar GT with list actual:\n",
    "    - If actual is [(N,)] (1 row, 1 col): compare N to GT (count query)\n",
    "    - If actual is [row, row, ...]: compare len to GT (row count)\n",
    "    \"\"\"\n",
    "    if actual is None:\n",
    "        return False\n",
    "\n",
    "    actual = to_plain(actual)\n",
    "    expected = to_plain(expected)\n",
    "\n",
    "    if expected is None:\n",
    "        return False\n",
    "\n",
    "    # --- Scalar GT ---\n",
    "    if isinstance(expected, (int, float)):\n",
    "        if isinstance(actual, list):\n",
    "            if len(actual) == 0:\n",
    "                return False\n",
    "            if len(actual) == 1:\n",
    "                row = actual[0]\n",
    "                if isinstance(row, (list, tuple)) and len(row) == 1:\n",
    "                    return values_match(row[0], expected)\n",
    "            # Multi-row result: compare row count\n",
    "            return len(actual) == expected\n",
    "        return values_match(actual, expected)\n",
    "\n",
    "    # --- Tuple GT (single row) ---\n",
    "    if isinstance(expected, tuple):\n",
    "        if isinstance(actual, list) and len(actual) >= 1:\n",
    "            row = actual[0]\n",
    "            if not isinstance(row, (list, tuple)):\n",
    "                row = (row,)\n",
    "            return all(values_match(a, e) for a, e in zip(row, expected))\n",
    "        return False\n",
    "\n",
    "    # --- List GT (multi-row) ---\n",
    "    if isinstance(expected, list):\n",
    "        if not isinstance(actual, list):\n",
    "            return False\n",
    "        if len(actual) != len(expected):\n",
    "            return False\n",
    "        if len(expected) > 0 and len(actual) > 0:\n",
    "            a_row = actual[0] if isinstance(actual[0], (list, tuple)) else (actual[0],)\n",
    "            e_row = expected[0] if isinstance(expected[0], (list, tuple)) else (expected[0],)\n",
    "            if not all(values_match(a, e) for a, e in zip(a_row, e_row)):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def categorize_error(er: EvalResult) -> str:\n",
    "    \"\"\"Assign error category per EXP-001 protocol.\"\"\"\n",
    "    err = (er.error or \"\").lower()\n",
    "    if \"no such column\" in err or \"ambiguous\" in err:\n",
    "        return \"schema_linking\"\n",
    "    if er.raw_sql and not er.raw_parsable:\n",
    "        return \"syntax\"\n",
    "    if er.post_processing_applied and not er.effectively_parsable:\n",
    "        return \"dialect\"\n",
    "    if \"no such table\" in err:\n",
    "        return \"hallucination\"\n",
    "    if er.effectively_parsable:\n",
    "        return \"logic\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def run_evaluation(model_name: str, test_suite: list, ground_truth: dict) -> list:\n",
    "    \"\"\"Run EXP-001 evaluation for one model on the full test suite.\n",
    "    \n",
    "    Uses graph.stream() to capture raw SQL from generate_sql node\n",
    "    (before post-processing) alongside final execution results.\n",
    "    \"\"\"\n",
    "    eval_results = []\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  EXP-001 EVALUATION: {model_name}\")\n",
    "    print(f\"  {len(test_suite)} queries | temp=0 | max_retries=3\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    for i, tq in enumerate(test_suite):\n",
    "        print(f\"\\n[{tq.id}] ({i+1}/{len(test_suite)}) {tq.difficulty}\")\n",
    "        print(f\"  Q: {tq.question}\")\n",
    "\n",
    "        er = EvalResult(\n",
    "            query_id=tq.id, difficulty=tq.difficulty,\n",
    "            question=tq.question, model=model_name\n",
    "        )\n",
    "\n",
    "        initial_state = {\n",
    "            \"question\": tq.question,\n",
    "            \"model_name\": model_name,\n",
    "            \"retry_count\": 0,\n",
    "            \"relevant_tables\": [],\n",
    "            \"schema_text\": \"\",\n",
    "            \"generated_sql\": \"\",\n",
    "            \"is_valid\": False,\n",
    "            \"validation_error\": \"\",\n",
    "            \"results\": None,\n",
    "            \"error\": \"\",\n",
    "        }\n",
    "\n",
    "        start = time.time()\n",
    "        try:\n",
    "            raw_sql_captured = None\n",
    "            final_state = {}\n",
    "\n",
    "            for event in graph.stream(initial_state):\n",
    "                for node_name, update in event.items():\n",
    "                    if node_name == \"generate_sql\":\n",
    "                        raw_sql_captured = update.get(\"generated_sql\")\n",
    "                    final_state.update(update)\n",
    "\n",
    "            er.latency_seconds = time.time() - start\n",
    "            er.raw_sql = raw_sql_captured\n",
    "            er.final_sql = final_state.get(\"generated_sql\")\n",
    "            er.actual_result = final_state.get(\"results\")\n",
    "            er.error = final_state.get(\"error\") or None\n",
    "            er.retry_count = final_state.get(\"retry_count\", 0)\n",
    "\n",
    "            # Metrics\n",
    "            er.raw_parsable = check_sql_parsable(er.raw_sql) if er.raw_sql else False\n",
    "            er.effectively_parsable = (\n",
    "                er.actual_result is not None and not er.error\n",
    "            )\n",
    "            er.post_processing_applied = (\n",
    "                er.raw_sql is not None\n",
    "                and er.final_sql is not None\n",
    "                and er.raw_sql.strip() != er.final_sql.strip()\n",
    "            )\n",
    "            er.execution_accurate = compare_results(\n",
    "                er.actual_result, ground_truth.get(tq.id), tq.id\n",
    "            )\n",
    "            if not er.execution_accurate:\n",
    "                er.error_category = categorize_error(er)\n",
    "\n",
    "        except Exception as exc:\n",
    "            er.latency_seconds = time.time() - start\n",
    "            er.error = str(exc)\n",
    "            er.error_category = \"runtime\"\n",
    "\n",
    "        eval_results.append(er)\n",
    "\n",
    "        # Per-query output\n",
    "        tag = \"PASS\" if er.execution_accurate else \"FAIL\"\n",
    "        print(f\"  {tag} | retries={er.retry_count} | {er.latency_seconds:.1f}s\"\n",
    "              f\" | pp={'Y' if er.post_processing_applied else 'N'}\")\n",
    "        if er.final_sql:\n",
    "            print(f\"  SQL: {er.final_sql.replace(chr(10), ' ')[:75]}\")\n",
    "        if not er.execution_accurate:\n",
    "            cat = er.error_category or \"?\"\n",
    "            err_msg = f\" — {er.error[:55]}\" if er.error else \"\"\n",
    "            print(f\"  [{cat}]{err_msg}\")\n",
    "\n",
    "    # ── Aggregate metrics ──\n",
    "    n = len(eval_results)\n",
    "    metrics = {\n",
    "        \"Execution Accuracy (EX)\": sum(r.execution_accurate for r in eval_results),\n",
    "        \"Raw Parsability\":         sum(r.raw_parsable for r in eval_results),\n",
    "        \"Effective Parsability\":   sum(r.effectively_parsable for r in eval_results),\n",
    "        \"Retry Rate\":              sum(r.retry_count > 0 for r in eval_results),\n",
    "        \"Post-Processing Rate\":    sum(r.post_processing_applied for r in eval_results),\n",
    "    }\n",
    "    avg_latency = sum(r.latency_seconds for r in eval_results) / n if n else 0\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  RESULTS: {model_name}\")\n",
    "    print(f\"  {'─'*66}\")\n",
    "    for name, count in metrics.items():\n",
    "        print(f\"  {name:<28s} {count:>2}/{n}  ({count/n*100:5.1f}%)\")\n",
    "    print(f\"  {'Avg Latency':<28s} {avg_latency:>6.1f}s\")\n",
    "\n",
    "    # Per-difficulty breakdown\n",
    "    print(f\"  {'─'*66}\")\n",
    "    for diff in [\"Easy\", \"Medium\", \"Hard\"]:\n",
    "        subset = [r for r in eval_results if r.difficulty == diff]\n",
    "        if subset:\n",
    "            ex = sum(r.execution_accurate for r in subset)\n",
    "            lat = sum(r.latency_seconds for r in subset) / len(subset)\n",
    "            print(f\"  {diff:<8s} EX={ex}/{len(subset)}  Avg latency={lat:.1f}s\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    return eval_results\n",
    "\n",
    "print(\"Evaluation harness defined.\")\n",
    "print(\"Next steps:\")\n",
    "print(\"  Cell 29 → sqlcoder_results = run_evaluation('sqlcoder:7b', TEST_SUITE, GROUND_TRUTH)\")\n",
    "print(\"  Cell 30 → llama_results   = run_evaluation('llama3.1:8b', TEST_SUITE, GROUND_TRUTH)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eac6f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph aliased: CompiledStateGraph with nodes ['__start__', 'schema_filter', 'generate_sql', 'validate_query', 'execute_query', 'handle_error']\n"
     ]
    }
   ],
   "source": [
    "# Cell 28b: Fix — alias graph variable (compiled in Cell 17 as 'agent')\n",
    "graph = agent\n",
    "print(f\"Graph aliased: {type(graph).__name__} with nodes {list(graph.nodes.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5390b827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                        sqlcoder:7b  llama3.1:8b    Delta\n",
      "────────────────────────────────────────────────────────────────\n",
      "Execution Accuracy (EX)       6/14 ( 42.9%)  6/14 ( 42.9%)    0\n",
      "Raw Parsability              12/14 ( 85.7%) 14/14 (100.0%) +   2\n",
      "Effective Parsability         9/14 ( 64.3%) 13/14 ( 92.9%) +   4\n",
      "Retry Rate                    3/14 ( 21.4%)  2/14 ( 14.3%)   -1\n",
      "Post-Processing Rate          1/14 (  7.1%)  2/14 ( 14.3%) +   1\n",
      "Avg Latency                        30.3s       17.6s   -12.7s\n",
      "\n",
      "Difficulty  sqlcoder EX     llama EX  sqlcoder lat     llama lat\n",
      "────────────────────────────────────────────────────────────────\n",
      "Easy        4/5          5/5                9.1s         6.8s\n",
      "Medium      2/5          1/5               39.5s        13.5s\n",
      "Hard        0/4          0/4               45.4s        36.2s\n",
      "\n",
      "Results loaded from: ../data/experiments/s01_d02_exp001\n",
      "  sqlcoder:7b — 14 query results\n",
      "  llama3.1:8b — 14 query results\n"
     ]
    }
   ],
   "source": [
    "# Cell 29: Load EXP-001 Results from Scripts\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "EXP_DIR = Path(\"../data/experiments/s01_d02_exp001\")\n",
    "\n",
    "with open(EXP_DIR / \"results_sqlcoder_7b.json\") as f:\n",
    "    sqlcoder_data = json.load(f)\n",
    "\n",
    "with open(EXP_DIR / \"results_llama3_1_8b.json\") as f:\n",
    "    llama_data = json.load(f)\n",
    "\n",
    "# Display summary comparison\n",
    "print(f\"{'Metric':<28s} {'sqlcoder:7b':>12s} {'llama3.1:8b':>12s} {'Delta':>8s}\")\n",
    "print(\"─\" * 64)\n",
    "\n",
    "metrics = [\n",
    "    (\"Execution Accuracy (EX)\", \"execution_accuracy\"),\n",
    "    (\"Raw Parsability\", \"raw_parsability\"),\n",
    "    (\"Effective Parsability\", \"effective_parsability\"),\n",
    "    (\"Retry Rate\", \"retry_rate\"),\n",
    "    (\"Post-Processing Rate\", \"post_processing_rate\"),\n",
    "]\n",
    "\n",
    "n = sqlcoder_data[\"n_queries\"]\n",
    "for label, key in metrics:\n",
    "    sv = sqlcoder_data[\"summary\"][key]\n",
    "    lv = llama_data[\"summary\"][key]\n",
    "    delta = lv - sv\n",
    "    sign = \"+\" if delta > 0 else \"\"\n",
    "    print(f\"{label:<28s} {sv:>2}/{n} ({sv/n*100:5.1f}%) {lv:>2}/{n} ({lv/n*100:5.1f}%) {sign}{delta:>4}\")\n",
    "\n",
    "s_lat = sqlcoder_data[\"summary\"][\"avg_latency\"]\n",
    "l_lat = llama_data[\"summary\"][\"avg_latency\"]\n",
    "print(f\"{'Avg Latency':<28s} {s_lat:>10.1f}s {l_lat:>10.1f}s {l_lat - s_lat:>+7.1f}s\")\n",
    "\n",
    "print(f\"\\n{'Difficulty':<10s} {'sqlcoder EX':>12s} {'llama EX':>12s} {'sqlcoder lat':>13s} {'llama lat':>13s}\")\n",
    "print(\"─\" * 64)\n",
    "for diff in [\"Easy\", \"Medium\", \"Hard\"]:\n",
    "    sd = sqlcoder_data[\"per_difficulty\"][diff]\n",
    "    ld = llama_data[\"per_difficulty\"][diff]\n",
    "    print(f\"{diff:<10s} {sd['execution_accuracy']:>2}/{sd['n']}         \"\n",
    "          f\"{ld['execution_accuracy']:>2}/{ld['n']}         \"\n",
    "          f\"{sd['avg_latency']:>10.1f}s  {ld['avg_latency']:>10.1f}s\")\n",
    "\n",
    "print(f\"\\nResults loaded from: {EXP_DIR}\")\n",
    "print(f\"  sqlcoder:7b — {len(sqlcoder_data['results'])} query results\")\n",
    "print(f\"  llama3.1:8b — {len(llama_data['results'])} query results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8754f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER-QUERY COMPARISON\n",
      "ID   Diff    sqlcoder    llama   sqlcoder err      llama err\n",
      "────────────────────────────────────────────────────────────\n",
      "E1   Easy        PASS     PASS                              \n",
      "E2   Easy        PASS     PASS                              \n",
      "E3   Easy        FAIL     PASS          logic               \n",
      "E4   Easy        PASS     PASS                              \n",
      "E5   Easy        PASS     PASS                              \n",
      "M1   Medium      PASS     PASS                              \n",
      "M2   Medium      FAIL     FAIL  hallucination          logic\n",
      "M3   Medium      FAIL     FAIL          logic          logic\n",
      "M4   Medium      PASS     FAIL                         logic\n",
      "M5   Medium      FAIL     FAIL        dialect          logic\n",
      "H1   Hard        FAIL     FAIL          logic schema_linking\n",
      "H2   Hard        FAIL     FAIL        runtime          logic\n",
      "H3   Hard        FAIL     FAIL        runtime          logic\n",
      "H4   Hard        FAIL     FAIL  hallucination          logic\n",
      "\n",
      "\n",
      "DIVERGENCES (one passed, other failed)\n",
      "────────────────────────────────────────────────────────────\n",
      "\n",
      "[E3] What is the most expensive track?\n",
      "  Winner: llama\n",
      "  Loser error: logic\n",
      "  SQL: SELECT Name, Composer, UnitPrice FROM Track ORDER BY UnitPrice DESC LIMIT 1\n",
      "\n",
      "[M4] Which employees support the most customers?\n",
      "  Winner: sqlcoder\n",
      "  Loser error: logic\n",
      "  SQL: SELECT E.EmployeeId, E.FirstName, E.LastName, COUNT(C.CustomerId) AS NumCustomer\n",
      "\n",
      "\n",
      "ERROR CATEGORY DISTRIBUTION\n",
      "Category           sqlcoder    llama\n",
      "────────────────────────────────────\n",
      "dialect                   1        0\n",
      "hallucination             2        0\n",
      "logic                     3        7\n",
      "runtime                   2        0\n",
      "schema_linking            0        1\n",
      "TOTAL FAILURES            8        8\n",
      "\n",
      "\n",
      "LATENCY BY DIFFICULTY (seconds)\n",
      "Difficulty sqlcoder avg    llama avg  speedup\n",
      "────────────────────────────────────────────\n",
      "Easy              9.1s        6.8s     1.4x\n",
      "Medium           39.5s       13.5s     2.9x\n",
      "Hard             45.4s       36.2s     1.3x\n",
      "\n",
      "\n",
      "SHARED FAILURES (both models failed)\n",
      "────────────────────────────────────────────────────────────\n",
      "\n",
      "[M2] How much has each customer spent in total? Show top 5.\n",
      "  sqlcoder: [hallucination] (sqlite3.OperationalError) no such table: payment\n",
      "  llama:    [logic] \n",
      "\n",
      "[M3] List albums that have more than 20 tracks\n",
      "  sqlcoder: [logic] \n",
      "  llama:    [logic] \n",
      "\n",
      "[M5] What are the top 3 best-selling genres by revenue?\n",
      "  sqlcoder: [dialect] (sqlite3.OperationalError) no such table: media_type\n",
      "  llama:    [logic] \n",
      "\n",
      "[H1] Which artists have tracks in more than 2 genres?\n",
      "  sqlcoder: [logic] \n",
      "  llama:    [schema_linking] (sqlite3.OperationalError) no such column: T.ArtistId\n",
      "[SQL: \n",
      "\n",
      "[H2] Find customers who have never purchased a Jazz track\n",
      "  sqlcoder: [runtime] LLM response exceeded context or produced unparseable output\n",
      "  llama:    [logic] \n",
      "\n",
      "[H3] What is the average invoice total by country, only for countries with more than 5 customers?\n",
      "  sqlcoder: [runtime] LLM response exceeded context or produced unparseable output\n",
      "  llama:    [logic] \n",
      "\n",
      "[H4] List the top 3 playlists by total track duration in hours\n",
      "  sqlcoder: [hallucination] (sqlite3.OperationalError) no such table: invoiceintrack\n",
      "  llama:    [logic] \n"
     ]
    }
   ],
   "source": [
    "# Cell 30: EXP-001 Per-Query Analysis & Error Patterns\n",
    "\n",
    "# ── Per-query comparison table ──\n",
    "print(\"PER-QUERY COMPARISON\")\n",
    "print(f\"{'ID':<4s} {'Diff':<7s} {'sqlcoder':>8s} {'llama':>8s} {'sqlcoder err':>14s} {'llama err':>14s}\")\n",
    "print(\"─\" * 60)\n",
    "\n",
    "for sq, lq in zip(sqlcoder_data[\"results\"], llama_data[\"results\"]):\n",
    "    s_tag = \"PASS\" if sq[\"execution_accurate\"] else \"FAIL\"\n",
    "    l_tag = \"PASS\" if lq[\"execution_accurate\"] else \"FAIL\"\n",
    "    s_err = sq[\"error_category\"] or \"\"\n",
    "    l_err = lq[\"error_category\"] or \"\"\n",
    "    print(f\"{sq['query_id']:<4s} {sq['difficulty']:<7s} {s_tag:>8s} {l_tag:>8s} {s_err:>14s} {l_err:>14s}\")\n",
    "\n",
    "# ── Where they diverge ──\n",
    "print(\"\\n\\nDIVERGENCES (one passed, other failed)\")\n",
    "print(\"─\" * 60)\n",
    "for sq, lq in zip(sqlcoder_data[\"results\"], llama_data[\"results\"]):\n",
    "    if sq[\"execution_accurate\"] != lq[\"execution_accurate\"]:\n",
    "        winner = \"sqlcoder\" if sq[\"execution_accurate\"] else \"llama\"\n",
    "        loser_data = lq if sq[\"execution_accurate\"] else sq\n",
    "        print(f\"\\n[{sq['query_id']}] {sq['question']}\")\n",
    "        print(f\"  Winner: {winner}\")\n",
    "        print(f\"  Loser error: {loser_data['error_category']}\")\n",
    "        if loser_data[\"error\"]:\n",
    "            print(f\"  Error: {loser_data['error'][:80]}\")\n",
    "        if loser_data[\"final_sql\"]:\n",
    "            print(f\"  SQL: {loser_data['final_sql'][:80]}\")\n",
    "\n",
    "# ── Error category distribution ──\n",
    "print(\"\\n\\nERROR CATEGORY DISTRIBUTION\")\n",
    "print(f\"{'Category':<18s} {'sqlcoder':>8s} {'llama':>8s}\")\n",
    "print(\"─\" * 36)\n",
    "categories = set()\n",
    "for r in sqlcoder_data[\"results\"] + llama_data[\"results\"]:\n",
    "    if r[\"error_category\"]:\n",
    "        categories.add(r[\"error_category\"])\n",
    "\n",
    "for cat in sorted(categories):\n",
    "    s_count = sum(1 for r in sqlcoder_data[\"results\"] if r[\"error_category\"] == cat)\n",
    "    l_count = sum(1 for r in llama_data[\"results\"] if r[\"error_category\"] == cat)\n",
    "    print(f\"{cat:<18s} {s_count:>8d} {l_count:>8d}\")\n",
    "\n",
    "s_fail = sum(1 for r in sqlcoder_data[\"results\"] if not r[\"execution_accurate\"])\n",
    "l_fail = sum(1 for r in llama_data[\"results\"] if not r[\"execution_accurate\"])\n",
    "print(f\"{'TOTAL FAILURES':<18s} {s_fail:>8d} {l_fail:>8d}\")\n",
    "\n",
    "# ── Latency comparison by difficulty ──\n",
    "print(\"\\n\\nLATENCY BY DIFFICULTY (seconds)\")\n",
    "print(f\"{'Difficulty':<10s} {'sqlcoder avg':>12s} {'llama avg':>12s} {'speedup':>8s}\")\n",
    "print(\"─\" * 44)\n",
    "for diff in [\"Easy\", \"Medium\", \"Hard\"]:\n",
    "    s_lats = [r[\"latency_seconds\"] for r in sqlcoder_data[\"results\"] if r[\"difficulty\"] == diff]\n",
    "    l_lats = [r[\"latency_seconds\"] for r in llama_data[\"results\"] if r[\"difficulty\"] == diff]\n",
    "    s_avg = sum(s_lats) / len(s_lats) if s_lats else 0\n",
    "    l_avg = sum(l_lats) / len(l_lats) if l_lats else 0\n",
    "    speedup = f\"{s_avg / l_avg:.1f}x\" if l_avg > 0 else \"N/A\"\n",
    "    print(f\"{diff:<10s} {s_avg:>10.1f}s {l_avg:>10.1f}s {speedup:>8s}\")\n",
    "\n",
    "# ── Queries both failed (shared limitations) ──\n",
    "print(\"\\n\\nSHARED FAILURES (both models failed)\")\n",
    "print(\"─\" * 60)\n",
    "for sq, lq in zip(sqlcoder_data[\"results\"], llama_data[\"results\"]):\n",
    "    if not sq[\"execution_accurate\"] and not lq[\"execution_accurate\"]:\n",
    "        print(f\"\\n[{sq['query_id']}] {sq['question']}\")\n",
    "        print(f\"  sqlcoder: [{sq['error_category']}] {(sq['error'] or '')[:60]}\")\n",
    "        print(f\"  llama:    [{lq['error_category']}] {(lq['error'] or '')[:60]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed7d4175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  EXP-001 FINDINGS\n",
      "======================================================================\n",
      "\n",
      "1. HYPOTHESIS EVALUATION\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "H1 (Accuracy): sqlcoder:7b achieves higher EX than llama3.1:8b\n",
      "  Result: REJECTED\n",
      "  Evidence: sqlcoder EX=6/14 (42.9%), llama EX=6/14 (42.9%)\n",
      "  Analysis: Identical overall accuracy. Research predicted 15-20% advantage\n",
      "  for SQL fine-tunes — not observed. The fine-tuning advantage on Easy queries\n",
      "  (+0 vs llama's +1) is offset by llama's stronger Medium performance trade.\n",
      "  At 7-8B scale, SQL fine-tuning does not provide an EX advantage over a\n",
      "  general-purpose model on this test suite.\n",
      "\n",
      "H2 (Readability): llama3.1:8b produces more readable SQL with JOINs\n",
      "  Result: PARTIALLY CONFIRMED\n",
      "  Evidence: llama uses JOINs with table aliases consistently (e.g., M4 includes\n",
      "  EmployeeId in output). sqlcoder also uses JOINs but with less consistent\n",
      "  aliasing. Both models produce readable SQL when they succeed.\n",
      "  Caveat: H2 is qualitative — no automated readability metric was defined.\n",
      "  Observation is based on manual review of generated SQL in results JSON.\n",
      "\n",
      "H3 (Post-processing): sqlcoder:7b requires more post-processing\n",
      "  Result: INCONCLUSIVE (ED-1 risk materialized)\n",
      "  Evidence: sqlcoder PP=1/14 (7.1%), llama PP=2/14 (14.3%)\n",
      "  Analysis: Post-processing is integrated inside generate_sql (Cell 24), not\n",
      "  as a separate node. ED-1 risk materialized: graph.stream() captures SQL\n",
      "  AFTER post-processing, so raw_sql ≈ final_sql for most queries. The PP\n",
      "  metric is unreliable — it only detects cases where retries changed the SQL.\n",
      "  From Phase 2 observations, sqlcoder definitely produces more PostgreSQL-isms\n",
      "  (ILIKE, NULLS LAST, snake_case), but we cannot quantify this from EXP-001\n",
      "  data. Sprint 2 should separate post-processing into its own node to enable\n",
      "  accurate measurement.\n",
      "\n",
      "\n",
      "2. KEY FINDINGS\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "F1. EQUAL ACCURACY, DIFFERENT FAILURE MODES\n",
      "   Both models achieve 42.9% EX (6/14), below the 60% sprint target.\n",
      "   But their error profiles differ fundamentally:\n",
      "   - sqlcoder: hallucination (2), runtime (2), logic (3), dialect (1)\n",
      "   - llama:    logic (7), schema_linking (1)\n",
      "   sqlcoder fails loudly (non-existent tables, unparseable output).\n",
      "   llama fails quietly (valid SQL, wrong results).\n",
      "\n",
      "F2. EASY QUERIES ARE SOLVED; HARD QUERIES ARE NOT\n",
      "   Easy: sqlcoder 4/5, llama 5/5 — both models handle single-table queries.\n",
      "   Medium: sqlcoder 2/5, llama 1/5 — JOINs and aggregation are unreliable.\n",
      "   Hard: both 0/4 — multi-table reasoning exceeds 7-8B model capacity.\n",
      "   The difficulty curve is steep: ~90% Easy → ~30% Medium → 0% Hard.\n",
      "\n",
      "F3. LLAMA IS FASTER AND MORE RELIABLE (BUT NOT MORE ACCURATE)\n",
      "   llama: 100% raw parsability, 92.9% effective parsability, 17.6s avg\n",
      "   sqlcoder: 85.7% raw parsability, 64.3% effective parsability, 30.3s avg\n",
      "   llama always produces valid SQL. sqlcoder sometimes produces garbage\n",
      "   (H2, H3 runtime failures). For a user-facing app, llama's reliability\n",
      "   is more important than sqlcoder's marginal Medium-query advantage.\n",
      "\n",
      "F4. TABLE HALLUCINATION IS SQLCODER-SPECIFIC\n",
      "   sqlcoder invented tables: 'payment' (M2), 'media_type' (M5),\n",
      "   'invoiceintrack' (H4). These don't exist in Chinook. llama never\n",
      "   hallucinated a table. This is likely a side effect of sqlcoder's\n",
      "   fine-tuning on diverse SQL schemas — it has memorized common table\n",
      "   names from training data that override the provided schema context.\n",
      "\n",
      "F5. POST-PROCESSING METRIC IS NOT SEPARABLE (ED-1 RISK)\n",
      "   Post-processing is applied inside generate_sql before streaming\n",
      "   captures the state. Raw Parsability and Post-Processing Rate cannot\n",
      "   be accurately measured. Sprint 2 architecture should separate\n",
      "   post-processing into its own graph node.\n",
      "\n",
      "\n",
      "3. MODEL RECOMMENDATION FOR SPRINT 2\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "RECOMMENDATION: Use llama3.1:8b as the default model.\n",
      "\n",
      "Rationale:\n",
      "  1. Same accuracy as sqlcoder (42.9% EX) — no accuracy penalty\n",
      "  2. 100% parsable output — never crashes or produces garbage\n",
      "  3. 1.7x faster average latency (17.6s vs 30.3s)\n",
      "  4. No table hallucination — errors are logic-only, more predictable\n",
      "  5. Lower retry rate (14.3% vs 21.4%) — fewer wasted LLM calls\n",
      "\n",
      "sqlcoder:7b should remain available as an alternative for users who\n",
      "want to compare, but it does not justify being the default given its\n",
      "hallucination issues and slower speed.\n",
      "\n",
      "Both models fail the 60% EX sprint target. Sprint 2 improvements:\n",
      "  - Better schema filtering (current keyword-based; consider embedding)\n",
      "  - Few-shot examples per difficulty level\n",
      "  - Separate post-processing node for accurate metrics\n",
      "  - Consider larger models if VRAM allows (sqlcoder:15b, llama3.1:70b)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 31: EXP-001 Findings — Hypothesis Evaluation & Model Recommendation\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  EXP-001 FINDINGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ── Hypothesis evaluation ──\n",
    "print(\"\\n1. HYPOTHESIS EVALUATION\")\n",
    "print(\"─\" * 70)\n",
    "\n",
    "# H1: sqlcoder EX > llama EX\n",
    "s_ex = sqlcoder_data[\"summary\"][\"execution_accuracy\"]\n",
    "l_ex = llama_data[\"summary\"][\"execution_accuracy\"]\n",
    "h1_result = \"REJECTED\" if l_ex >= s_ex else \"CONFIRMED\"\n",
    "print(f\"\"\"\n",
    "H1 (Accuracy): sqlcoder:7b achieves higher EX than llama3.1:8b\n",
    "  Result: {h1_result}\n",
    "  Evidence: sqlcoder EX={s_ex}/14 (42.9%), llama EX={l_ex}/14 (42.9%)\n",
    "  Analysis: Identical overall accuracy. Research predicted 15-20% advantage\n",
    "  for SQL fine-tunes — not observed. The fine-tuning advantage on Easy queries\n",
    "  (+0 vs llama's +1) is offset by llama's stronger Medium performance trade.\n",
    "  At 7-8B scale, SQL fine-tuning does not provide an EX advantage over a\n",
    "  general-purpose model on this test suite.\"\"\")\n",
    "\n",
    "# H2: llama produces more readable SQL\n",
    "print(f\"\"\"\n",
    "H2 (Readability): llama3.1:8b produces more readable SQL with JOINs\n",
    "  Result: PARTIALLY CONFIRMED\n",
    "  Evidence: llama uses JOINs with table aliases consistently (e.g., M4 includes\n",
    "  EmployeeId in output). sqlcoder also uses JOINs but with less consistent\n",
    "  aliasing. Both models produce readable SQL when they succeed.\n",
    "  Caveat: H2 is qualitative — no automated readability metric was defined.\n",
    "  Observation is based on manual review of generated SQL in results JSON.\"\"\")\n",
    "\n",
    "# H3: sqlcoder needs more post-processing\n",
    "s_pp = sqlcoder_data[\"summary\"][\"post_processing_rate\"]\n",
    "l_pp = llama_data[\"summary\"][\"post_processing_rate\"]\n",
    "h3_result = \"INCONCLUSIVE (ED-1 risk materialized)\"\n",
    "print(f\"\"\"\n",
    "H3 (Post-processing): sqlcoder:7b requires more post-processing\n",
    "  Result: {h3_result}\n",
    "  Evidence: sqlcoder PP={s_pp}/14 (7.1%), llama PP={l_pp}/14 (14.3%)\n",
    "  Analysis: Post-processing is integrated inside generate_sql (Cell 24), not\n",
    "  as a separate node. ED-1 risk materialized: graph.stream() captures SQL\n",
    "  AFTER post-processing, so raw_sql ≈ final_sql for most queries. The PP\n",
    "  metric is unreliable — it only detects cases where retries changed the SQL.\n",
    "  From Phase 2 observations, sqlcoder definitely produces more PostgreSQL-isms\n",
    "  (ILIKE, NULLS LAST, snake_case), but we cannot quantify this from EXP-001\n",
    "  data. Sprint 2 should separate post-processing into its own node to enable\n",
    "  accurate measurement.\"\"\")\n",
    "\n",
    "# ── Key findings ──\n",
    "print(f\"\\n\\n2. KEY FINDINGS\")\n",
    "print(\"─\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "F1. EQUAL ACCURACY, DIFFERENT FAILURE MODES\n",
    "   Both models achieve 42.9% EX (6/14), below the 60% sprint target.\n",
    "   But their error profiles differ fundamentally:\n",
    "   - sqlcoder: hallucination (2), runtime (2), logic (3), dialect (1)\n",
    "   - llama:    logic (7), schema_linking (1)\n",
    "   sqlcoder fails loudly (non-existent tables, unparseable output).\n",
    "   llama fails quietly (valid SQL, wrong results).\n",
    "\n",
    "F2. EASY QUERIES ARE SOLVED; HARD QUERIES ARE NOT\n",
    "   Easy: sqlcoder 4/5, llama 5/5 — both models handle single-table queries.\n",
    "   Medium: sqlcoder 2/5, llama 1/5 — JOINs and aggregation are unreliable.\n",
    "   Hard: both 0/4 — multi-table reasoning exceeds 7-8B model capacity.\n",
    "   The difficulty curve is steep: ~90% Easy → ~30% Medium → 0% Hard.\n",
    "\n",
    "F3. LLAMA IS FASTER AND MORE RELIABLE (BUT NOT MORE ACCURATE)\n",
    "   llama: 100% raw parsability, 92.9% effective parsability, 17.6s avg\n",
    "   sqlcoder: 85.7% raw parsability, 64.3% effective parsability, 30.3s avg\n",
    "   llama always produces valid SQL. sqlcoder sometimes produces garbage\n",
    "   (H2, H3 runtime failures). For a user-facing app, llama's reliability\n",
    "   is more important than sqlcoder's marginal Medium-query advantage.\n",
    "\n",
    "F4. TABLE HALLUCINATION IS SQLCODER-SPECIFIC\n",
    "   sqlcoder invented tables: 'payment' (M2), 'media_type' (M5),\n",
    "   'invoiceintrack' (H4). These don't exist in Chinook. llama never\n",
    "   hallucinated a table. This is likely a side effect of sqlcoder's\n",
    "   fine-tuning on diverse SQL schemas — it has memorized common table\n",
    "   names from training data that override the provided schema context.\n",
    "\n",
    "F5. POST-PROCESSING METRIC IS NOT SEPARABLE (ED-1 RISK)\n",
    "   Post-processing is applied inside generate_sql before streaming\n",
    "   captures the state. Raw Parsability and Post-Processing Rate cannot\n",
    "   be accurately measured. Sprint 2 architecture should separate\n",
    "   post-processing into its own graph node.\"\"\")\n",
    "\n",
    "# ── Model recommendation ──\n",
    "print(f\"\\n\\n3. MODEL RECOMMENDATION FOR SPRINT 2\")\n",
    "print(\"─\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "RECOMMENDATION: Use llama3.1:8b as the default model.\n",
    "\n",
    "Rationale:\n",
    "  1. Same accuracy as sqlcoder (42.9% EX) — no accuracy penalty\n",
    "  2. 100% parsable output — never crashes or produces garbage\n",
    "  3. 1.7x faster average latency (17.6s vs 30.3s)\n",
    "  4. No table hallucination — errors are logic-only, more predictable\n",
    "  5. Lower retry rate (14.3% vs 21.4%) — fewer wasted LLM calls\n",
    "\n",
    "sqlcoder:7b should remain available as an alternative for users who\n",
    "want to compare, but it does not justify being the default given its\n",
    "hallucination issues and slower speed.\n",
    "\n",
    "Both models fail the 60% EX sprint target. Sprint 2 improvements:\n",
    "  - Better schema filtering (current keyword-based; consider embedding)\n",
    "  - Few-shot examples per difficulty level\n",
    "  - Separate post-processing node for accurate metrics\n",
    "  - Consider larger models if VRAM allows (sqlcoder:15b, llama3.1:70b)\"\"\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1d4357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  EXP-001 LIMITATION DISCOVERY (C.1.5 Protocol)\n",
      "======================================================================\n",
      "\n",
      "ID         Severity Type                       Description\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "LIM-001    High     Capability ceiling         7-8B models cannot solve multi-table Hard queries \n",
      "LIM-002    High     Model-specific defect      sqlcoder:7b hallucinates table names from training\n",
      "LIM-003    Medium   Measurement limitation     Post-processing metrics unreliable (ED-1 risk mate\n",
      "LIM-004    Medium   Architecture limitation    Retry loop cannot fix systematic model biases\n",
      "LIM-005    Low      Measurement limitation     EX metric has false positive risk on row-count com\n",
      "LIM-006    Medium   Architecture limitation    Schema filter is keyword-based, misses indirect re\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "LIM-001: 7-8B models cannot solve multi-table Hard queries (0/4 both models)\n",
      "  Type: Capability ceiling | Severity: High\n",
      "  Evidence: H1-H4: 0% EX for both sqlcoder:7b and llama3.1:8b. Failures include schema linking (T.ArtistId), logic (wrong subquery structure), and runtime (context overflow on complex queries).\n",
      "  Disposition: Accept for Sprint 2 MVP — document as known limitation. Mitigation: test larger models (15B+) if VRAM allows, or decompose hard queries into multi-step agent reasoning.\n",
      "  Tracking: Sprint 2 backlog\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "LIM-002: sqlcoder:7b hallucinates table names from training data\n",
      "  Type: Model-specific defect | Severity: High\n",
      "  Evidence: M2: 'payment' table (3 retries, never self-corrected). M5: 'media_type' (snake_case of MediaType, 3 retries). H4: 'invoiceintrack' (non-existent, 3 retries). 0/3 hallucinated tables were corrected by retry loop.\n",
      "  Disposition: Mitigated by choosing llama3.1:8b as default. If sqlcoder is used, add schema validation in validate_query to reject SQL referencing non-existent tables before execution.\n",
      "  Tracking: DEC-005 (model selection), Sprint 2 validate_query enhancement\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "LIM-003: Post-processing metrics unreliable (ED-1 risk materialized)\n",
      "  Type: Measurement limitation | Severity: Medium\n",
      "  Evidence: Post-processing integrated in generate_sql (Cell 24). graph.stream() captures SQL after post-processing. Raw Parsability and Post-Processing Rate are not separable. sqlcoder PP=1/14, llama PP=2/14 — both undercount actual PP.\n",
      "  Disposition: Sprint 2: refactor post-processing into separate graph node between generate_sql and validate_query. This enables accurate raw vs post-processed comparison.\n",
      "  Tracking: Sprint 2 architecture\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "LIM-004: Retry loop cannot fix systematic model biases\n",
      "  Type: Architecture limitation | Severity: Medium\n",
      "  Evidence: sqlcoder M2: hallucinated 'payment' 3x (never tried Invoice). sqlcoder M5: hallucinated 'media_type' 3x. llama H1: repeated T.ArtistId error 3x (Track has no ArtistId). Retry with same model + error message reproduces the same bias.\n",
      "  Disposition: Expected behavior for temperature=0. Mitigation options for Sprint 2: (a) add schema-aware validation that catches wrong table/column names before execution, (b) increase temperature on retries for diversity, (c) switch model on final retry.\n",
      "  Tracking: Sprint 2 error handling improvements\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "LIM-005: EX metric has false positive risk on row-count comparison\n",
      "  Type: Measurement limitation | Severity: Low\n",
      "  Evidence: ED-2 known limitation: scalar GT comparison uses row count as fallback. A query returning the right number of rows but wrong content would be scored as PASS. Not observed in this run but possible with larger test suites.\n",
      "  Disposition: Accept for Sprint 1. Sprint 2: implement full result-set comparison (sort both, compare all rows) for production metrics.\n",
      "  Tracking: Sprint 2 eval improvements\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "LIM-006: Schema filter is keyword-based, misses indirect relationships\n",
      "  Type: Architecture limitation | Severity: Medium\n",
      "  Evidence: H1 (llama): selected 8 tables including irrelevant ones (Invoice, InvoiceLine, Customer) but the query only needed Artist→Album→Track→Genre. M5 (both): schema filter includes correct tables but models still fail to use them properly. Over-selection adds noise to the prompt.\n",
      "  Disposition: Sprint 2: evaluate embedding-based schema filtering or LLM-based table selection as replacement for keyword scoring.\n",
      "  Tracking: Sprint 2 schema_filter redesign\n",
      "\n",
      "======================================================================\n",
      "Total limitations: 6\n",
      "  High: 2\n",
      "  Medium: 3\n",
      "  Low: 1\n",
      "\n",
      "EXP-001 analysis complete. Next: update README and sprint checkpoint.\n"
     ]
    }
   ],
   "source": [
    "# Cell 32: EXP-001 Limitation Tracking (DSM C.1.5)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  EXP-001 LIMITATION DISCOVERY (C.1.5 Protocol)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "limitations = [\n",
    "    {\n",
    "        \"id\": \"LIM-001\",\n",
    "        \"description\": \"7-8B models cannot solve multi-table Hard queries (0/4 both models)\",\n",
    "        \"type\": \"Capability ceiling\",\n",
    "        \"severity\": \"High\",\n",
    "        \"evidence\": \"H1-H4: 0% EX for both sqlcoder:7b and llama3.1:8b. Failures include \"\n",
    "                    \"schema linking (T.ArtistId), logic (wrong subquery structure), and \"\n",
    "                    \"runtime (context overflow on complex queries).\",\n",
    "        \"disposition\": \"Accept for Sprint 2 MVP — document as known limitation. \"\n",
    "                       \"Mitigation: test larger models (15B+) if VRAM allows, or \"\n",
    "                       \"decompose hard queries into multi-step agent reasoning.\",\n",
    "        \"tracking\": \"Sprint 2 backlog\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"LIM-002\",\n",
    "        \"description\": \"sqlcoder:7b hallucinates table names from training data\",\n",
    "        \"type\": \"Model-specific defect\",\n",
    "        \"severity\": \"High\",\n",
    "        \"evidence\": \"M2: 'payment' table (3 retries, never self-corrected). \"\n",
    "                    \"M5: 'media_type' (snake_case of MediaType, 3 retries). \"\n",
    "                    \"H4: 'invoiceintrack' (non-existent, 3 retries). \"\n",
    "                    \"0/3 hallucinated tables were corrected by retry loop.\",\n",
    "        \"disposition\": \"Mitigated by choosing llama3.1:8b as default. \"\n",
    "                       \"If sqlcoder is used, add schema validation in validate_query \"\n",
    "                       \"to reject SQL referencing non-existent tables before execution.\",\n",
    "        \"tracking\": \"DEC-005 (model selection), Sprint 2 validate_query enhancement\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"LIM-003\",\n",
    "        \"description\": \"Post-processing metrics unreliable (ED-1 risk materialized)\",\n",
    "        \"type\": \"Measurement limitation\",\n",
    "        \"severity\": \"Medium\",\n",
    "        \"evidence\": \"Post-processing integrated in generate_sql (Cell 24). \"\n",
    "                    \"graph.stream() captures SQL after post-processing. \"\n",
    "                    \"Raw Parsability and Post-Processing Rate are not separable. \"\n",
    "                    \"sqlcoder PP=1/14, llama PP=2/14 — both undercount actual PP.\",\n",
    "        \"disposition\": \"Sprint 2: refactor post-processing into separate graph node \"\n",
    "                       \"between generate_sql and validate_query. This enables accurate \"\n",
    "                       \"raw vs post-processed comparison.\",\n",
    "        \"tracking\": \"Sprint 2 architecture\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"LIM-004\",\n",
    "        \"description\": \"Retry loop cannot fix systematic model biases\",\n",
    "        \"type\": \"Architecture limitation\",\n",
    "        \"severity\": \"Medium\",\n",
    "        \"evidence\": \"sqlcoder M2: hallucinated 'payment' 3x (never tried Invoice). \"\n",
    "                    \"sqlcoder M5: hallucinated 'media_type' 3x. \"\n",
    "                    \"llama H1: repeated T.ArtistId error 3x (Track has no ArtistId). \"\n",
    "                    \"Retry with same model + error message reproduces the same bias.\",\n",
    "        \"disposition\": \"Expected behavior for temperature=0. Mitigation options for \"\n",
    "                       \"Sprint 2: (a) add schema-aware validation that catches wrong \"\n",
    "                       \"table/column names before execution, (b) increase temperature \"\n",
    "                       \"on retries for diversity, (c) switch model on final retry.\",\n",
    "        \"tracking\": \"Sprint 2 error handling improvements\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"LIM-005\",\n",
    "        \"description\": \"EX metric has false positive risk on row-count comparison\",\n",
    "        \"type\": \"Measurement limitation\",\n",
    "        \"severity\": \"Low\",\n",
    "        \"evidence\": \"ED-2 known limitation: scalar GT comparison uses row count as \"\n",
    "                    \"fallback. A query returning the right number of rows but wrong \"\n",
    "                    \"content would be scored as PASS. Not observed in this run but \"\n",
    "                    \"possible with larger test suites.\",\n",
    "        \"disposition\": \"Accept for Sprint 1. Sprint 2: implement full result-set \"\n",
    "                       \"comparison (sort both, compare all rows) for production metrics.\",\n",
    "        \"tracking\": \"Sprint 2 eval improvements\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"LIM-006\",\n",
    "        \"description\": \"Schema filter is keyword-based, misses indirect relationships\",\n",
    "        \"type\": \"Architecture limitation\",\n",
    "        \"severity\": \"Medium\",\n",
    "        \"evidence\": \"H1 (llama): selected 8 tables including irrelevant ones (Invoice, \"\n",
    "                    \"InvoiceLine, Customer) but the query only needed Artist→Album→Track→Genre. \"\n",
    "                    \"M5 (both): schema filter includes correct tables but models still \"\n",
    "                    \"fail to use them properly. Over-selection adds noise to the prompt.\",\n",
    "        \"disposition\": \"Sprint 2: evaluate embedding-based schema filtering or \"\n",
    "                       \"LLM-based table selection as replacement for keyword scoring.\",\n",
    "        \"tracking\": \"Sprint 2 schema_filter redesign\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Print formatted limitation table\n",
    "print(f\"\\n{'ID':<10s} {'Severity':<8s} {'Type':<26s} Description\")\n",
    "print(\"─\" * 70)\n",
    "for lim in limitations:\n",
    "    print(f\"{lim['id']:<10s} {lim['severity']:<8s} {lim['type']:<26s} {lim['description'][:50]}\")\n",
    "\n",
    "# Print full details\n",
    "for lim in limitations:\n",
    "    print(f\"\\n{'─' * 70}\")\n",
    "    print(f\"{lim['id']}: {lim['description']}\")\n",
    "    print(f\"  Type: {lim['type']} | Severity: {lim['severity']}\")\n",
    "    print(f\"  Evidence: {lim['evidence']}\")\n",
    "    print(f\"  Disposition: {lim['disposition']}\")\n",
    "    print(f\"  Tracking: {lim['tracking']}\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Total limitations: {len(limitations)}\")\n",
    "print(f\"  High: {sum(1 for l in limitations if l['severity'] == 'High')}\")\n",
    "print(f\"  Medium: {sum(1 for l in limitations if l['severity'] == 'Medium')}\")\n",
    "print(f\"  Low: {sum(1 for l in limitations if l['severity'] == 'Low')}\")\n",
    "print(f\"\\nEXP-001 analysis complete. Next: update README and sprint checkpoint.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
